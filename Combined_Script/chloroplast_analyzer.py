#!/usr/bin/env python3
"""
Chloroplast Genome Analysis Module
===================================

A comprehensive module for chloroplast genome analysis with 7 modes.

Author: Abdullah
Date: December 2025
Version: 2.0.2 (Fixed rps12 counting)

Usage:
    from chloroplast_analyzer import (
        run_mode_1,
        run_mode_2,
        run_mode_3,
        run_mode_4,
        run_mode_5,
        run_mode_6,
        run_mode_7,
        run_all_modes
    )
    
    # Run specific mode
    run_mode_1()
    
    # Or run all modes
    run_all_modes()

Requirements:
    pip install biopython pandas openpyxl numpy python-docx

Modes:
    Mode 1: Gene Content Analysis - Counts genes and classifies them
    Mode 2: Gene Length Analysis - Calculates gene lengths (rps12 counted once)
    Mode 3: IR Boundary Analysis - Analyzes inverted repeat boundaries
    Mode 4: Codon Usage Analysis - Calculates codon frequencies
    Mode 5: Amino Acid Analysis - Analyzes amino acid composition
    Mode 6: SNP Analysis - Detects SNPs from FASTA alignments
    Mode 7: Intron Analysis - Extracts intron information
"""

import os
import sys


# ============================================================================
# MODE 1: Gene Content Analysis
# ============================================================================

_MODE_1_CODE = '#!/usr/bin/env python3\n"""\nChloroplast Genome Gene Comparative Analysis Tool\n==================================================\n\nThis script performs comprehensive analysis of chloroplast genome annotations from\nGenBank files. It identifies genes, classifies them as functional or pseudogenes, detects IR-mediated duplications,\nand produces publication-ready Excel reports.\n\nAuthor: Abdullah\nDate: December 2025\nVersion: 1.0\n\nRequirements:\n    - Python 3.7+\n    - biopython\n    - pandas\n    - openpyxl (for Excel writing)\n\nUsage:\n    Place this script in a folder containing GenBank (.gb, .gbk, .genbank) files\n    and run:\n        python chloroplast_analyzer.py\n    \n    Output will be generated as an Excel file with timestamp in the same directory.\n\nCitation:\n    If you use this tool in your research, please cite [appropriate reference]\n"""\n\nimport os\nimport re\nfrom collections import defaultdict\nfrom datetime import datetime\nfrom typing import List, Tuple, Dict, Set\nfrom Bio import SeqIO\nfrom Bio.SeqFeature import SeqFeature\nimport pandas as pd\nfrom openpyxl.styles import Font\n\n\n# ============================================================================\n# CONFIGURATION\n# ============================================================================\n\n# Automatically use current working directory\nWORKING_DIR = os.getcwd()\n\n# Generate timestamped output filename for version control\nTIMESTAMP = datetime.now().strftime("%Y%m%d_%H%M%S")\nOUTPUT_FILE = os.path.join(WORKING_DIR, f"Chloroplast_Gene_Analysis_{TIMESTAMP}.xlsx")\n\n# Gap tolerance for merging nearby gene features (bp)\nGAP_TOLERANCE = 0\n\n# GenBank file extensions to process\nGENBANK_EXTENSIONS = (\'.gb\', \'.gbk\', \'.genbank\')\n\n\n# ============================================================================\n# UTILITY FUNCTIONS\n# ============================================================================\n\ndef extract_species_name(filename: str) -> str:\n    """\n    Extract clean species name from GenBank filename.\n    \n    Removes file extensions (.gb, .gbk, .genbank) and standardizes the name\n    for publication-quality output.\n    \n    Args:\n        filename: Original GenBank filename\n        \n    Returns:\n        Clean species name without extension\n        \n    Examples:\n        \'Solanum_lycopersicum.gb\' -> \'Solanum_lycopersicum\'\n        \'Species_name.gbk\' -> \'Species_name\'\n    """\n    # Remove common GenBank extensions\n    name = filename\n    for ext in GENBANK_EXTENSIONS:\n        if name.lower().endswith(ext):\n            name = name[:-len(ext)]\n            break\n    \n    return name.strip()\n\ndef get_gene_name_from_qualifiers(qualifiers: Dict) -> str:\n    """\n    Extract gene name from GenBank feature qualifiers.\n    \n    Searches through common qualifier fields in priority order to identify\n    the most appropriate gene name. This ensures consistent naming across\n    different annotation styles.\n    \n    Args:\n        qualifiers: Dictionary of GenBank feature qualifiers\n        \n    Returns:\n        Gene name as string, or None if no suitable name found\n        \n    Priority order:\n        1. gene - Standard gene symbol (e.g., \'rbcL\', \'psbA\')\n        2. locus_tag - Systematic locus identifier\n        3. product - Gene product description\n        4. protein_id - Protein accession\n        5. note - Additional annotations\n    """\n    for key in ("gene", "locus_tag", "product", "protein_id", "note"):\n        if key in qualifiers and qualifiers[key]:\n            value = qualifiers[key][0].strip()\n            if value:\n                # Replace spaces with underscores for consistent naming\n                return value.replace(" ", "_")\n    return None\n\n\ndef detect_inverted_repeat_regions(record: SeqIO.SeqRecord) -> Tuple[List[Tuple[int, int]], \n                                                                       List[Tuple[int, int]]]:\n    """\n    Identify inverted repeat regions (IRa and IRb) in chloroplast genome.\n    \n    Chloroplast genomes typically have two large inverted repeats (IRa and IRb)\n    that separate the large and small single-copy regions. This function detects\n    these regions from GenBank annotations.\n    \n    Args:\n        record: BioPython SeqRecord object from GenBank file\n        \n    Returns:\n        Tuple of two lists: (IRa_ranges, IRb_ranges)\n        Each range is a tuple of (start, end) coordinates\n        \n    Notes:\n        - Searches \'repeat_region\' and \'misc_feature\' annotations\n        - Identifies IR regions by keywords: "inverted repeat", "ira", "irb"\n        - Merges overlapping or adjacent annotations\n    """\n    ira_ranges = []\n    irb_ranges = []\n    \n    # Search all features for IR annotations\n    for feature in record.features:\n        if feature.type.lower() in ("repeat_region", "misc_feature"):\n            # Collect all descriptive text from multiple qualifier fields\n            annotation_text = []\n            for key in ("note", "product", "description"):\n                if key in feature.qualifiers:\n                    annotation_text.append(" ".join(feature.qualifiers[key]))\n            \n            combined_text = " ".join(annotation_text).lower()\n            \n            # Check if this feature describes an inverted repeat\n            if "inverted repeat" in combined_text or "ira" in combined_text or "irb" in combined_text:\n                span = (int(feature.location.start), int(feature.location.end))\n                \n                # Classify as IRa or IRb based on annotation text\n                if "ira" in combined_text or "ir a" in combined_text:\n                    ira_ranges.append(span)\n                elif "irb" in combined_text or "ir b" in combined_text:\n                    irb_ranges.append(span)\n    \n    # Merge overlapping or adjacent ranges\n    return _merge_genomic_ranges(ira_ranges), _merge_genomic_ranges(irb_ranges)\n\n\ndef _merge_genomic_ranges(ranges: List[Tuple[int, int]]) -> List[Tuple[int, int]]:\n    """\n    Merge overlapping or adjacent genomic coordinate ranges.\n    \n    Args:\n        ranges: List of (start, end) coordinate tuples\n        \n    Returns:\n        List of merged (start, end) tuples with no overlaps\n        \n    Example:\n        [(100, 200), (150, 250), (300, 400)] -> [(100, 250), (300, 400)]\n    """\n    if not ranges:\n        return []\n    \n    # Sort ranges by start position\n    sorted_ranges = sorted(ranges)\n    merged = [list(sorted_ranges[0])]\n    \n    for start, end in sorted_ranges[1:]:\n        # Check if current range overlaps or is adjacent to last merged range\n        if start <= merged[-1][1] + 1:\n            # Extend the last merged range\n            merged[-1][1] = max(merged[-1][1], end)\n        else:\n            # Add as new separate range\n            merged.append([start, end])\n    \n    return [(start, end) for start, end in merged]\n\n\ndef check_span_overlap(span1: Tuple[int, int], span2: Tuple[int, int]) -> bool:\n    """\n    Test if two genomic coordinate spans overlap.\n    \n    Args:\n        span1: First span as (start, end)\n        span2: Second span as (start, end)\n        \n    Returns:\n        True if spans overlap, False otherwise\n    """\n    start1, end1 = span1\n    start2, end2 = span2\n    return not (end1 < start2 or end2 < start1)\n\n\ndef merge_feature_spans(spans: List[Tuple[int, int]], \n                        gap_tolerance: int = 0) -> List[Tuple[int, int]]:\n    """\n    Merge gene feature spans that are within gap_tolerance of each other.\n    \n    Some genes may be annotated as multiple features (e.g., exons). This function\n    merges features that belong to the same gene based on proximity.\n    \n    Args:\n        spans: List of (start, end) coordinate tuples\n        gap_tolerance: Maximum gap (bp) to bridge when merging\n        \n    Returns:\n        List of merged (start, end) tuples\n    """\n    if not spans:\n        return []\n    \n    sorted_spans = sorted(spans)\n    merged = [list(sorted_spans[0])]\n    \n    for start, end in sorted_spans[1:]:\n        # Check if within gap tolerance of previous span\n        if start <= merged[-1][1] + gap_tolerance + 1:\n            merged[-1][1] = max(merged[-1][1], end)\n        else:\n            merged.append([start, end])\n    \n    return [(start, end) for start, end in merged]\n\n\ndef classify_gene_locus(features: List[SeqFeature]) -> str:\n    """\n    Classify a gene locus as functional or pseudogene.\n    \n    Classification logic:\n        - Functional: Has CDS, tRNA, or rRNA with product annotation\n        - Pseudogene: Explicitly marked as pseudo OR lacks protein-coding features\n    \n    Args:\n        features: List of BioPython SeqFeature objects for this locus\n        \n    Returns:\n        Classification string: "functional" or "pseudogene"\n        \n    Notes:\n        - Prioritizes explicit pseudogene annotations\n        - Considers both feature types and qualifier content\n        - tRNA/rRNA require product annotation to be considered functional\n    """\n    has_cds = False\n    has_trna = False\n    has_rrna = False\n    has_product = False\n    explicit_pseudo = False\n    \n    for feature in features:\n        qualifiers = feature.qualifiers\n        \n        # Check CDS (protein-coding) features\n        if feature.type == "CDS":\n            if "pseudo" in qualifiers:\n                explicit_pseudo = True\n            \n            product_text = " ".join(\n                qualifiers.get("product", []) + qualifiers.get("note", [])\n            ).lower()\n            \n            if "pseudo" in product_text or "pseudogene" in product_text:\n                explicit_pseudo = True\n            else:\n                has_cds = True\n        \n        # Check tRNA features\n        if feature.type == "tRNA":\n            has_trna = True\n            product_text = " ".join(\n                qualifiers.get("product", []) + qualifiers.get("note", [])\n            ).strip()\n            if product_text:\n                has_product = True\n        \n        # Check rRNA features\n        if feature.type == "rRNA":\n            has_rrna = True\n            product_text = " ".join(\n                qualifiers.get("product", []) + qualifiers.get("note", [])\n            ).strip()\n            if product_text:\n                has_product = True\n        \n        # Check for product annotation (any feature type)\n        if "product" in qualifiers and qualifiers["product"]:\n            product_text = " ".join(qualifiers["product"]).strip().lower()\n            if product_text and "pseudo" not in product_text and "pseudogene" not in product_text:\n                has_product = True\n            elif "pseudo" in product_text or "pseudogene" in product_text:\n                explicit_pseudo = True\n        \n        # Check note field for pseudogene annotations\n        if "note" in qualifiers and qualifiers["note"]:\n            note_text = " ".join(qualifiers["note"]).lower()\n            if "pseudogene" in note_text or "pseudo" in note_text:\n                explicit_pseudo = True\n    \n    # Classification decision\n    if has_cds or has_trna or has_rrna or has_product:\n        return "functional"\n    return "pseudogene"\n\n\n# ============================================================================\n# MAIN ANALYSIS FUNCTIONS\n# ============================================================================\n\ndef analyze_genbank_file(filepath: str) -> List[Dict]:\n    """\n    Analyze a single GenBank file for gene content and IR duplications.\n    \n    This is the main analysis function that:\n        1. Detects IR regions (IRa and IRb)\n        2. Identifies all genes and their features\n        3. Classifies genes as functional or pseudogenes\n        4. Determines copy number and IR duplication status\n    \n    Args:\n        filepath: Path to GenBank file\n        \n    Returns:\n        List of dictionaries, each containing analysis results for one gene:\n            - Genome: Filename of source\n            - Gene Name: Gene identifier\n            - Copies: Number of copies detected\n            - Functional / Pseudogene: Gene status\n            - Duplicate Status: Detailed copy number and location info\n    """\n    # Parse GenBank file\n    record = SeqIO.read(filepath, "genbank")\n    \n    # Detect inverted repeat regions\n    ira_ranges, irb_ranges = detect_inverted_repeat_regions(record)\n    \n    # Collect all gene-related features\n    gene_features = defaultdict(list)\n    \n    for feature in record.features:\n        # Only process gene-related feature types\n        if feature.type not in ("CDS", "tRNA", "rRNA", "gene"):\n            continue\n        \n        # Get or generate gene name\n        gene_name = get_gene_name_from_qualifiers(feature.qualifiers)\n        if not gene_name:\n            # Generate systematic name for unannotated ORFs\n            start = int(feature.location.start)\n            end = int(feature.location.end)\n            strand = "-" if feature.location.strand == -1 else "+"\n            gene_name = f"ORF_{start}_{end}_{strand}"\n        \n        gene_features[gene_name].append(feature)\n    \n    # Analyze each gene\n    results = []\n    for gene_name, features in sorted(gene_features.items()):\n        # Extract genomic coordinates for all features of this gene\n        span_feature_pairs = [\n            (int(f.location.start), int(f.location.end), f) \n            for f in features\n        ]\n        spans = [(start, end) for start, end, _ in span_feature_pairs]\n        \n        # Merge nearby features into loci (handles multi-exon genes)\n        locus_spans = merge_feature_spans(spans, gap_tolerance=GAP_TOLERANCE)\n        \n        # Analyze each locus separately\n        locus_info_list = []\n        for locus_span in locus_spans:\n            locus_start, locus_end = locus_span\n            \n            # Get all features overlapping this locus\n            locus_features = [\n                feature for start, end, feature in span_feature_pairs\n                if not (end < locus_start or start > locus_end)\n            ]\n            \n            # Classify locus as functional or pseudogene\n            classification = classify_gene_locus(locus_features)\n            \n            # Determine genomic region (IRa, IRb, or single copy)\n            in_ira = any(check_span_overlap(locus_span, ir) for ir in ira_ranges)\n            in_irb = any(check_span_overlap(locus_span, ir) for ir in irb_ranges)\n            \n            if in_ira and in_irb:\n                region = "IR(both)"  # Rare: spans both IR regions\n            elif in_ira:\n                region = "IRa"\n            elif in_irb:\n                region = "IRb"\n            else:\n                region = "single_copy"\n            \n            locus_info_list.append({\n                "span": locus_span,\n                "classification": classification,\n                "region": region\n            })\n        \n        # Summarize gene-level statistics\n        total_copies = len(locus_info_list)\n        regions = {locus["region"] for locus in locus_info_list}\n        is_ir_duplicated = ("IRa" in regions) and ("IRb" in regions)\n        \n        functional_copies = sum(\n            1 for locus in locus_info_list \n            if locus["classification"] == "functional"\n        )\n        pseudogene_copies = sum(\n            1 for locus in locus_info_list \n            if locus["classification"] == "pseudogene"\n        )\n        \n        # Overall gene status (functional if any copy is functional)\n        gene_status = "functional" if functional_copies > 0 else "pseudogene"\n        \n        # Generate detailed duplication status string\n        if is_ir_duplicated:\n            if functional_copies > 1 and pseudogene_copies == 0:\n                dup_status = f"{functional_copies} functional copies (IRa+IRb)"\n            elif functional_copies >= 1 and pseudogene_copies >= 1:\n                dup_status = (f"{functional_copies} functional + "\n                             f"{pseudogene_copies} pseudogene copies (IRa+IRb)")\n            elif functional_copies == 0 and pseudogene_copies >= 1:\n                dup_status = f"{pseudogene_copies} pseudogene copies (IRa+IRb)"\n            else:\n                dup_status = f"{total_copies} copies (IRa+IRb)"\n        else:\n            if total_copies == 1:\n                dup_status = "single copy"\n            else:\n                if functional_copies >= 1 and pseudogene_copies == 0:\n                    dup_status = f"{functional_copies} functional copies (not IR-duplicated)"\n                elif functional_copies >= 1 and pseudogene_copies >= 1:\n                    dup_status = (f"{functional_copies} functional + "\n                                 f"{pseudogene_copies} pseudogene copies (not IR-duplicated)")\n                else:\n                    dup_status = f"{pseudogene_copies} pseudogene copies (not IR-duplicated)"\n        \n        # Store results for this gene\n        results.append({\n            "Genome": extract_species_name(os.path.basename(filepath)),\n            "Gene Name": gene_name,\n            "Copies": total_copies,\n            "Functional / Pseudogene": gene_status,\n            "Duplicate Status": dup_status\n        })\n    \n    return results\n\n\ndef generate_summary_statistics(all_results: List[Dict], \n                                genome_gene_map: Dict[str, Set[str]]) -> pd.DataFrame:\n    """\n    Generate genome-level summary statistics.\n    \n    Calculates aggregate statistics for each genome:\n        - Total unique genes\n        - Number of functional genes\n        - Number of pseudogenes\n        - Number of IR-duplicated genes\n    \n    Args:\n        all_results: List of all gene analysis results\n        genome_gene_map: Dictionary mapping genome names to their gene sets\n        \n    Returns:\n        DataFrame with summary statistics per genome\n    """\n    summary_data = []\n    \n    for genome_name, gene_set in genome_gene_map.items():\n        genome_results = [r for r in all_results if r["Genome"] == genome_name]\n        \n        # Count unique functional and pseudogene genes\n        functional_genes = set()\n        pseudogene_genes = set()\n        ir_duplicated_count = 0\n        \n        for result in genome_results:\n            if result["Functional / Pseudogene"] == "functional":\n                functional_genes.add(result["Gene Name"])\n            elif result["Functional / Pseudogene"] == "pseudogene":\n                pseudogene_genes.add(result["Gene Name"])\n            \n            # Count IR-duplicated genes\n            if "IRa+IRb" in result["Duplicate Status"]:\n                ir_duplicated_count += 1\n        \n        summary_data.append({\n            "Genome": genome_name,\n            "Total Genes": len(gene_set),\n            "Functional Genes": len(functional_genes),\n            "Pseudogene Genes": len(pseudogene_genes),\n            "IR-duplicated Genes": ir_duplicated_count\n        })\n    \n    return pd.DataFrame(\n        summary_data,\n        columns=["Genome", "Total Genes", "Functional Genes", \n                "Pseudogene Genes", "IR-duplicated Genes"]\n    )\n\n\ndef identify_unique_genes(all_results: List[Dict], \n                         genome_gene_map: Dict[str, Set[str]]) -> Tuple[pd.DataFrame, pd.DataFrame]:\n    """\n    Identify genes with unique presence/absence patterns.\n    \n    Returns two types of unique genes:\n    1. Genes present in only ONE genome (genome-specific)\n    2. Genes missing from only ONE genome (nearly universal)\n    \n    Args:\n        all_results: List of all gene analysis results\n        genome_gene_map: Dictionary mapping genome names to their gene sets\n        \n    Returns:\n        Tuple of two DataFrames: (genome_specific_genes, nearly_universal_genes)\n    """\n    genome_specific_data = []\n    nearly_universal_data = []\n    \n    # Get all unique genes across all genomes\n    all_genes = set()\n    for genes in genome_gene_map.values():\n        all_genes.update(genes)\n    \n    # For each gene, count how many genomes contain it\n    gene_presence = defaultdict(list)\n    for genome_name, gene_set in genome_gene_map.items():\n        for gene_name in all_genes:\n            if gene_name in gene_set:\n                gene_presence[gene_name].append(genome_name)\n    \n    total_genomes = len(genome_gene_map)\n    \n    # Identify genome-specific genes (present in only 1 genome)\n    for gene_name, genomes_with_gene in gene_presence.items():\n        if len(genomes_with_gene) == 1:\n            genome_name = genomes_with_gene[0]\n            gene_result = next(\n                r for r in all_results \n                if r["Genome"] == genome_name and r["Gene Name"] == gene_name\n            )\n            genome_specific_data.append(gene_result)\n    \n    # Identify nearly universal genes (missing from only 1 genome)\n    if total_genomes > 2:  # Only meaningful with 3+ genomes\n        for gene_name, genomes_with_gene in gene_presence.items():\n            if len(genomes_with_gene) == total_genomes - 1:\n                # Find which genome is missing this gene\n                missing_genome = None\n                for genome_name in genome_gene_map.keys():\n                    if genome_name not in genomes_with_gene:\n                        missing_genome = genome_name\n                        break\n                \n                # Add entry for each genome that HAS the gene\n                for genome_name in genomes_with_gene:\n                    gene_result = next(\n                        r for r in all_results \n                        if r["Genome"] == genome_name and r["Gene Name"] == gene_name\n                    ).copy()\n                    gene_result["Missing_From"] = missing_genome\n                    nearly_universal_data.append(gene_result)\n    \n    df_specific = pd.DataFrame(\n        genome_specific_data,\n        columns=["Genome", "Gene Name", "Copies", \n                "Functional / Pseudogene", "Duplicate Status"]\n    )\n    \n    df_nearly_universal = pd.DataFrame(\n        nearly_universal_data,\n        columns=["Genome", "Gene Name", "Copies", \n                "Functional / Pseudogene", "Duplicate Status", "Missing_From"]\n    )\n    \n    return df_specific, df_nearly_universal\n\n\ndef apply_publication_formatting(writer: pd.ExcelWriter, sheet_name: str):\n    """\n    Apply publication-quality formatting to Excel worksheet.\n    \n    Formatting includes:\n        - Auto-adjusted column widths\n        - Frozen header row\n        - Italic formatting for species names (Genome column)\n        - Italic formatting for gene names (Gene Name column)\n    \n    Args:\n        writer: pandas ExcelWriter object\n        sheet_name: Name of the worksheet to format\n    """\n    worksheet = writer.sheets[sheet_name]\n    italic_font = Font(italic=True)\n    \n    # Get column indices for species and gene names\n    genome_col = None\n    gene_col = None\n    missing_col = None\n    \n    # Find column letters for Genome, Gene Name, and Missing_From\n    for col_idx, column in enumerate(worksheet.iter_cols(1, worksheet.max_column, 1, 1), start=1):\n        header_value = column[0].value\n        if header_value == "Genome":\n            genome_col = col_idx\n        elif header_value == "Gene Name":\n            gene_col = col_idx\n        elif header_value == "Missing_From":\n            missing_col = col_idx\n    \n    # Apply italic formatting to species names and gene names\n    for row_idx in range(2, worksheet.max_row + 1):  # Start from row 2 (skip header)\n        # Italicize species names in Genome column\n        if genome_col:\n            cell = worksheet.cell(row=row_idx, column=genome_col)\n            cell.font = italic_font\n        \n        # Italicize gene names in Gene Name column\n        if gene_col:\n            cell = worksheet.cell(row=row_idx, column=gene_col)\n            cell.font = italic_font\n        \n        # Italicize species names in Missing_From column (if exists)\n        if missing_col:\n            cell = worksheet.cell(row=row_idx, column=missing_col)\n            if cell.value:  # Only if not empty\n                cell.font = italic_font\n    \n    # Auto-adjust column widths\n    for column in worksheet.columns:\n        max_length = 0\n        column_letter = column[0].column_letter\n        \n        for cell in column:\n            try:\n                if cell.value and len(str(cell.value)) > max_length:\n                    max_length = len(str(cell.value))\n            except:\n                pass\n        \n        # Set width with reasonable limits\n        adjusted_width = min(max_length + 3, 50)\n        worksheet.column_dimensions[column_letter].width = adjusted_width\n    \n    # Freeze header row for easy scrolling\n    worksheet.freeze_panes = worksheet[\'A2\']\n\n\n# ============================================================================\n# MAIN EXECUTION\n# ============================================================================\n\ndef main():\n    """\n    Main execution function.\n    \n    Workflow:\n        1. Find all GenBank files in current directory\n        2. Analyze each file\n        3. Generate summary statistics\n        4. Identify unique genes\n        5. Write publication-ready Excel report\n    """\n    print("=" * 70)\n    print("Chloroplast Genome Gene Comparative Analysis")\n    print("=" * 70)\n    print(f"\\nWorking directory: {WORKING_DIR}")\n    \n    # Find all GenBank files\n    genbank_files = sorted([\n        f for f in os.listdir(WORKING_DIR)\n        if f.lower().endswith(GENBANK_EXTENSIONS)\n    ])\n    \n    if not genbank_files:\n        print(f"\\nERROR: No GenBank files found in {WORKING_DIR}")\n        print(f"Supported extensions: {\', \'.join(GENBANK_EXTENSIONS)}")\n        return\n    \n    print(f"\\nFound {len(genbank_files)} GenBank file(s):")\n    for filename in genbank_files:\n        print(f"  - {filename}")\n    \n    # Process all files\n    print("\\n" + "-" * 70)\n    print("Processing files...")\n    print("-" * 70)\n    \n    all_results = []\n    genome_gene_map = defaultdict(set)\n    \n    for genbank_file in genbank_files:\n        filepath = os.path.join(WORKING_DIR, genbank_file)\n        species_name = extract_species_name(genbank_file)\n        print(f"\\nAnalyzing: {species_name}")\n        \n        try:\n            results = analyze_genbank_file(filepath)\n            all_results.extend(results)\n            genome_gene_map[species_name] = set(r["Gene Name"] for r in results)\n            print(f"  ✓ Found {len(results)} genes")\n        except Exception as e:\n            print(f"  ✗ Error processing file: {str(e)}")\n            continue\n    \n    if not all_results:\n        print("\\nERROR: No results generated. Check your GenBank files.")\n        return\n    \n    # Generate analysis outputs\n    print("\\n" + "-" * 70)\n    print("Generating analysis reports...")\n    print("-" * 70)\n    \n    # 1. Complete gene table\n    df_gene_table = pd.DataFrame(\n        all_results,\n        columns=["Genome", "Gene Name", "Copies", \n                "Functional / Pseudogene", "Duplicate Status"]\n    )\n    \n    # 2. Summary statistics\n    df_summary = generate_summary_statistics(all_results, genome_gene_map)\n    \n    # 3. Unique genes (genome-specific and nearly universal)\n    df_genome_specific, df_nearly_universal = identify_unique_genes(all_results, genome_gene_map)\n    \n    # Write Excel file with publication-quality formatting\n    print(f"\\nWriting results to: {OUTPUT_FILE}")\n    \n    with pd.ExcelWriter(OUTPUT_FILE, engine=\'openpyxl\') as writer:\n        # Write each sheet\n        df_gene_table.to_excel(writer, sheet_name="Gene_Table", index=False)\n        df_summary.to_excel(writer, sheet_name="Summary", index=False)\n        df_genome_specific.to_excel(writer, sheet_name="Genome_Specific_Genes", index=False)\n        if not df_nearly_universal.empty:\n            df_nearly_universal.to_excel(writer, sheet_name="Nearly_Universal_Genes", index=False)\n        \n        # Apply publication formatting to all sheets\n        for sheet_name in writer.sheets:\n            apply_publication_formatting(writer, sheet_name)\n    \n    # Print summary\n    print("\\n" + "=" * 70)\n    print("ANALYSIS COMPLETE")\n    print("=" * 70)\n    print(f"\\nTotal genomes analyzed: {len(genome_gene_map)}")\n    print(f"Total genes identified: {len(set(r[\'Gene Name\'] for r in all_results))}")\n    print(f"Total gene records: {len(all_results)}")\n    \n    print("\\nOutput file contains up to 4 sheets:")\n    print("  1. Gene_Table: Complete gene catalog with duplication status")\n    print("  2. Summary: Genome-level statistics")\n    print("  3. Genome_Specific_Genes: Genes found in only ONE genome")\n    if not df_nearly_universal.empty:\n        print("  4. Nearly_Universal_Genes: Genes missing from only ONE genome")\n    \n    print(f"\\nResults saved to: {OUTPUT_FILE}")\n    print("\\n" + "=" * 70)\n\n\nif True:\n    main()'

def run_mode_1():
    """
    Mode 1: Gene Content Analysis
    
    This function executes the original script code for Mode 1.
    All logic and output formatting is preserved from the original script.
    
    Returns:
        None - Outputs are saved as Excel/Word files
        
    Raises:
        FileNotFoundError: If required input files are not found
        Exception: For other errors during execution
    """
    print("\n" + "="*80)
    print(f"MODE 1: Gene Content Analysis")
    print("="*80 + "\n")
    
    exec(_MODE_1_CODE, globals())


# ============================================================================
# MODE 2: Gene Length Analysis
# ============================================================================

_MODE_2_CODE = 'import pandas as pd\nfrom Bio import SeqIO\nfrom docx import Document\nfrom docx.shared import Pt, Inches, RGBColor\nfrom docx.enum.text import WD_ALIGN_PARAGRAPH\nfrom docx.oxml.ns import qn\nfrom docx.oxml import OxmlElement\nimport os\nimport glob\n\n# Mapping for showing both names\nname_map = {\n    "pafI": "ycf3 (pafI)",\n    "pafII": "ycf4 (pafII)", \n    "lhbA": "psbZ (lhbA)",\n    "pbf1": "psbN (pbf1)",\n    "ycf3": "ycf3 (pafI)",\n    "ycf4": "ycf4 (pafII)",\n    "psbZ": "psbZ (lhbA)",\n    "psbN": "psbN (pbf1)"\n}\n\n# Function to get display name\ndef get_display_name(gene_name):\n    """Convert gene name to display format"""\n    return name_map.get(gene_name, gene_name)\n\n# Function to check if a gene or tRNA has introns\ndef has_introns(features, gene_name, feature_type="CDS"):\n    gene_features = [\n        f for f in features\n        if f.type == feature_type and gene_name in f.qualifiers.get("gene", [])\n    ]\n    for feature in gene_features:\n        if hasattr(feature.location, "parts") and len(feature.location.parts) > 1:\n            return True\n    return False\n\n# Extract gene content\ndef extract_gene_content(genbank_file):\n    gene_data = {\n        "Category for genes": [],\n        "Group of genes": [],\n        "Name of genes": [],\n        "Amount": []\n    }\n\n    intron_containing_cds = set()\n    intron_containing_trna = set()\n\n    for record in SeqIO.parse(genbank_file, "genbank"):\n        gene_count = {}\n\n        for feature in record.features:\n            if feature.type == "gene":\n                gene_name = feature.qualifiers.get("gene", [""])[0]\n\n                if gene_name:\n                    # Convert to display name\n                    display_name = get_display_name(gene_name)\n\n                    # Check introns on ORIGINAL gene name\n                    if has_introns(record.features, gene_name, "CDS"):\n                        intron_containing_cds.add(display_name)\n                        display_name += "*"\n                    elif has_introns(record.features, gene_name, "tRNA"):\n                        intron_containing_trna.add(display_name)\n                        display_name += "*"\n\n                    # Count occurrences\n                    gene_count[display_name] = gene_count.get(display_name, 0) + 1\n\n        # Define gene categories\n        categories = {\n            "Self-replication": [\n                ("Large subunit of ribosome", "rpl"),\n                ("Small subunit of ribosome", "rps"),\n                ("DNA dependent RNA polymerase", "rpo"),\n                ("rRNA genes", "rrn"),\n                ("tRNA genes", "trn")\n            ],\n            "Photosynthesis": [\n                ("Photosystem Ⅰ", "psa"),\n                ("Photosystem Ⅱ", "psb"),\n                ("NADPH dehydrogenase", "ndh"),\n                ("Cytochrome b/f complex", "pet"),\n                ("Subunits of ATP synthase", "atp"),\n                ("Large subunit of Rubisco", "rbc"),\n                # ONLY ycf3 and ycf4 in Photosynthesis assembly genes\n                ("Photosynthesis assembly genes", ["ycf3 (pafI)", "ycf4 (pafII)"])\n            ],\n            "Other genes": [\n                ("Protease", "clp"),\n                ("Maturase", "mat"),\n                ("Envelop membrane protein", "cem"),\n                ("Subunit of Acetyl-CoA-carboxylase", "acc"),\n                ("C-type cytochrome synthesis gene", "ccs"),\n                ("Translation initiation factor", "infA"),\n                # Conserved open reading frames (excluding ycf3 and ycf4)\n                ("Conserved open reading frames", lambda gene: gene.startswith("ycf") \n                 and not gene.startswith("ycf3") and not gene.startswith("ycf4"))\n            ]\n        }\n\n        categorized_genes = set()\n\n        for category, groups in categories.items():\n            for group_name, pattern in groups:\n                matched_genes = {}\n                \n                # Handle different pattern types\n                if callable(pattern):\n                    # Use callable function for matching\n                    for k, v in gene_count.items():\n                        k_no_star = k.replace("*", "")\n                        if pattern(k_no_star):\n                            matched_genes[k] = v\n                elif isinstance(pattern, list):\n                    # Exact match for list of specific gene names\n                    for k, v in gene_count.items():\n                        k_no_star = k.replace("*", "")\n                        if k_no_star in pattern:\n                            matched_genes[k] = v\n                else:\n                    # String prefix match\n                    for k, v in gene_count.items():\n                        k_no_star = k.replace("*", "")\n                        if k_no_star.startswith(pattern):\n                            matched_genes[k] = v\n                \n                if matched_genes:\n                    categorized_genes.update(matched_genes.keys())\n                    \n                    sorted_genes = sorted(matched_genes.items())\n                    \n                    gene_data["Category for genes"].append(category)\n                    gene_data["Group of genes"].append(group_name)\n                    # Use superscript \'a\' for duplicates instead of (2)\n                    gene_data["Name of genes"].append(\n                        ", ".join([f"{k}^a" if v > 1 and "rps12" not in k.lower() else k for k, v in sorted_genes])\n                    )\n                    # Count rps12 as 1 gene (trans-spliced), others as their actual count\n                    total_count = sum([1 if "rps12" in k.lower() else v for k, v in matched_genes.items()])\n                    gene_data["Amount"].append(total_count)\n\n        # Remaining genes (Excluding genes)\n        excluding_genes = {k: v for k, v in gene_count.items()\n                          if k not in categorized_genes}\n\n        if excluding_genes:\n            gene_data["Category for genes"].append("Excluding genes")\n            gene_data["Group of genes"].append("Excluding genes")\n            sorted_excluding = sorted(excluding_genes.items())\n            gene_data["Name of genes"].append(\n                ", ".join([f"{k}^a" if v > 1 and "rps12" not in k.lower() else k for k, v in sorted_excluding])\n            )\n            # Count rps12 as 1 gene (trans-spliced), others as their actual count\n            total_count = sum([1 if "rps12" in k.lower() else v for k, v in excluding_genes.items()])\n            gene_data["Amount"].append(total_count)\n\n    # Add total row\n    total_genes = sum(gene_data["Amount"])\n    gene_data["Category for genes"].append("")\n    gene_data["Group of genes"].append("")\n    gene_data["Name of genes"].append("Total number of genes")\n    gene_data["Amount"].append(total_genes)\n\n    return pd.DataFrame(gene_data), {\n        "CDS with introns": list(intron_containing_cds),\n        "tRNA with introns": list(intron_containing_trna)\n    }\n\n# Function to add superscript\ndef add_superscript(run, text):\n    """Add superscript formatting to a run"""\n    run.font.superscript = True\n    run.text = text\n\n# Function to set cell borders\ndef set_cell_border(cell, **kwargs):\n    """Set cell borders for professional table appearance"""\n    tc = cell._element\n    tcPr = tc.get_or_add_tcPr()\n    \n    for edge in (\'top\', \'left\', \'bottom\', \'right\'):\n        edge_tag = \'w:{}\'.format(edge)\n        edge_element = tcPr.find(qn(edge_tag))\n        if edge_element is None:\n            edge_element = OxmlElement(edge_tag)\n            tcPr.append(edge_element)\n        \n        # Set border properties\n        if edge in kwargs:\n            for key, value in kwargs[edge].items():\n                edge_element.set(qn(\'w:{}\'.format(key)), str(value))\n\n# Word formatting with superscript support\ndef add_italic_text_with_superscript(cell, text):\n    """Add italic text with superscript \'a\' for duplicates and * for introns"""\n    cell.text = ""\n    p = cell.add_paragraph()\n    gene_names = text.split(", ")\n    \n    for i, gene_name in enumerate(gene_names):\n        if i > 0:\n            p.add_run(", ")\n        \n        # Check for both markers\n        has_intron = "*" in gene_name\n        has_duplicate = "^a" in gene_name\n        \n        # Remove markers to get base name\n        base_name = gene_name.replace("*", "").replace("^a", "")\n        \n        # Add base name in italic\n        run = p.add_run(base_name)\n        run.italic = True\n        \n        # Add markers based on what\'s present\n        if has_intron and has_duplicate:\n            # Both markers: *, a\n            asterisk = p.add_run("*")\n            asterisk.italic = True\n            comma_sup = p.add_run(", ")\n            comma_sup.italic = True\n            add_superscript(comma_sup, ", ")\n            a_sup = p.add_run("a")\n            a_sup.italic = True\n            add_superscript(a_sup, "a")\n        elif has_intron:\n            # Only intron marker: *\n            asterisk = p.add_run("*")\n            asterisk.italic = True\n        elif has_duplicate:\n            # Only duplicate marker: a (superscript, no comma)\n            a_sup = p.add_run("a")\n            a_sup.italic = True\n            add_superscript(a_sup, "a")\n\ndef create_table(df, output_file):\n    doc = Document()\n    \n    # Set document margins for better layout\n    sections = doc.sections\n    for section in sections:\n        section.top_margin = Inches(1)\n        section.bottom_margin = Inches(1)\n        section.left_margin = Inches(1)\n        section.right_margin = Inches(1)\n    \n    # Add table title\n    title = doc.add_paragraph()\n    title_run = title.add_run("Table S1. Gene content of the chloroplast genome")\n    title_run.bold = True\n    title_run.font.size = Pt(12)\n    title.alignment = WD_ALIGN_PARAGRAPH.LEFT\n    \n    # Create table\n    table = doc.add_table(rows=1, cols=len(df.columns))\n    table.style = \'Table Grid\'\n    \n    # Format header row\n    hdr = table.rows[0].cells\n    header_labels = ["Category for genes", "Group of genes", "Name of genes", "Gene number"]\n    \n    for i, label in enumerate(header_labels):\n        hdr[i].text = label\n        # Bold header text\n        for paragraph in hdr[i].paragraphs:\n            for run in paragraph.runs:\n                run.font.bold = True\n                run.font.size = Pt(10)\n            paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER\n        # Center align header cells vertically\n        tc = hdr[i]._element\n        tcPr = tc.get_or_add_tcPr()\n        tcVAlign = OxmlElement(\'w:vAlign\')\n        tcVAlign.set(qn(\'w:val\'), \'center\')\n        tcPr.append(tcVAlign)\n    \n    # Store rows by category for merging\n    category_rows = {}\n    current_category = None\n    \n    for idx, row in df.iterrows():\n        cells = table.add_row().cells\n        row_index = len(table.rows) - 1\n        \n        category = str(row["Category for genes"])\n        \n        # Track rows for each category\n        if category and category != "":\n            if category not in category_rows:\n                category_rows[category] = []\n            category_rows[category].append(row_index)\n            \n            # Only write category name in first occurrence\n            if category != current_category:\n                cells[0].text = category\n                current_category = category\n            else:\n                cells[0].text = ""  # Leave empty for subsequent rows\n        else:\n            cells[0].text = ""\n            current_category = None\n        \n        cells[1].text = str(row["Group of genes"])\n        \n        if row["Name of genes"] == "Total number of genes":\n            cells[2].text = row["Name of genes"]\n            # Bold the total row\n            for paragraph in cells[2].paragraphs:\n                for run in paragraph.runs:\n                    run.font.bold = True\n            for paragraph in cells[3].paragraphs:\n                for run in paragraph.runs:\n                    run.font.bold = True\n        else:\n            add_italic_text_with_superscript(cells[2], row["Name of genes"])\n        \n        cells[3].text = str(row["Amount"])\n        \n        # Set font size for all cells\n        for cell in cells:\n            for paragraph in cell.paragraphs:\n                for run in paragraph.runs:\n                    run.font.size = Pt(10)\n    \n    # Merge cells for each category and center align\n    for category, row_indices in category_rows.items():\n        if len(row_indices) > 1:\n            # Get the first cell\n            first_cell = table.rows[row_indices[0]].cells[0]\n            \n            # Merge with all subsequent cells in this category\n            for i in range(1, len(row_indices)):\n                first_cell.merge(table.rows[row_indices[i]].cells[0])\n            \n            # Center align the merged cell\n            first_cell.paragraphs[0].alignment = WD_ALIGN_PARAGRAPH.CENTER\n            # Also set vertical alignment to center\n            tc = first_cell._element\n            tcPr = tc.get_or_add_tcPr()\n            tcVAlign = OxmlElement(\'w:vAlign\')\n            tcVAlign.set(qn(\'w:val\'), \'center\')\n            tcPr.append(tcVAlign)\n    \n    # Set column widths for better appearance\n    widths = [Inches(1.5), Inches(2.2), Inches(3.5), Inches(0.8)]\n    for row in table.rows:\n        for idx, width in enumerate(widths):\n            row.cells[idx].width = width\n    \n    # Add notes at the end\n    doc.add_paragraph()\n    notes = doc.add_paragraph()\n    notes_run = notes.add_run("Note: ")\n    notes_run.bold = True\n    notes_run.font.size = Pt(10)\n    \n    text_run = notes.add_run("*, ")\n    text_run.font.size = Pt(10)\n    \n    sup_run = notes.add_run("a")\n    sup_run.font.size = Pt(10)\n    add_superscript(sup_run, "a")\n    \n    final_text = notes.add_run(" indicate genes containing introns and duplicated genes in inverted repeat (IR) regions, respectively. The ")\n    final_text.font.size = Pt(10)\n    \n    # Add italic rps12\n    rps12_run = notes.add_run("rps12")\n    rps12_run.font.size = Pt(10)\n    rps12_run.italic = True\n    \n    # Continue with rest of note\n    trans_text = notes.add_run(" gene is a trans-spliced gene and is not marked as duplicated despite appearing in multiple locations.")\n    trans_text.font.size = Pt(10)\n\n    doc.save(output_file)\n    print(f"✓ Saved: {output_file}")\n\n# Process a single GenBank file\ndef process_genbank_file(genbank_file):\n    """Process a single GenBank file and create its Word document"""\n    # Extract filename without extension for output naming\n    base_name = os.path.splitext(os.path.basename(genbank_file))[0]\n    output_file = f"Table_{base_name}.docx"\n    \n    print(f"\\nProcessing: {genbank_file}")\n    \n    try:\n        df, introns = extract_gene_content(genbank_file)\n        create_table(df, output_file)\n        \n        print(f"  CDS with introns: {introns[\'CDS with introns\']}")\n        print(f"  tRNA with introns: {introns[\'tRNA with introns\']}")\n        \n        return True\n    except Exception as e:\n        print(f"✗ Error processing {genbank_file}: {str(e)}")\n        return False\n\n# MAIN\ndef main():\n    # Find all .gb files in the current directory\n    gb_files = glob.glob("*.gb")\n    \n    if not gb_files:\n        print("No .gb files found in the current directory!")\n        return\n    \n    print(f"Found {len(gb_files)} GenBank file(s):")\n    for f in gb_files:\n        print(f"  - {f}")\n    \n    print("\\n" + "="*60)\n    \n    # Process each file\n    success_count = 0\n    for gb_file in gb_files:\n        if process_genbank_file(gb_file):\n            success_count += 1\n    \n    print("\\n" + "="*60)\n    print(f"\\nSummary: Successfully processed {success_count}/{len(gb_files)} file(s)")\n\nif True:\n    main()'

def run_mode_2():
    """
    Mode 2: Gene Length Analysis
    
    This function executes the original script code for Mode 2.
    All logic and output formatting is preserved from the original script.
    
    Returns:
        None - Outputs are saved as Excel/Word files
        
    Raises:
        FileNotFoundError: If required input files are not found
        Exception: For other errors during execution
    """
    print("\n" + "="*80)
    print(f"MODE 2: Gene Length Analysis")
    print("="*80 + "\n")
    
    exec(_MODE_2_CODE, globals())


# ============================================================================
# MODE 3: IR Boundary Analysis
# ============================================================================

_MODE_3_CODE = 'import os\nimport pandas as pd\nfrom Bio import SeqIO\nfrom openpyxl import load_workbook\nfrom openpyxl.styles import Font, Alignment, PatternFill, Border, Side\nfrom openpyxl.utils import get_column_letter\n\n# Function to calculate GC content with rounding to two decimal places\ndef calculate_gc(sequence):\n    total_bases = len(sequence)\n    gc_count = sequence.count(\'G\') + sequence.count(\'C\')\n    return round((gc_count / total_bases) * 100, 2) if total_bases > 0 else 0\n\n# Initialize list to store results\nresults = []\n\n# Use current working directory\nfolder_path = os.getcwd()\n\n# Loop through .gb and .gbf files in the folder\nfor filename in os.listdir(folder_path):\n    if filename.endswith(\'.gb\') or filename.endswith(\'.gbf\'):\n        record_path = os.path.join(folder_path, filename)\n        record = SeqIO.read(record_path, \'genbank\')\n        \n        # Basic genome information\n        species = record.annotations[\'organism\']\n        genome_length = len(record.seq)\n        accession_number = record.annotations.get(\'accessions\', [\'N/A\'])[0]\n        \n        # Initialize variables for LSC and SSC regions\n        lsc_feature = ssc_feature = None\n        \n        # Search for LSC and SSC in feature notes\n        for feature in record.features:\n            if \'note\' in feature.qualifiers:\n                note_value = feature.qualifiers[\'note\'][0].lower()\n                if any(keyword in note_value for keyword in ["large single copy (lsc)", "large single copy region (lsc)", "lsc"]):\n                    lsc_feature = feature\n                elif any(keyword in note_value for keyword in ["small single copy region (ssc)", "small single copy (ssc)", "ssc"]):\n                    ssc_feature = feature\n        \n        # Calculate exact lengths of LSC and SSC\n        lsc_length = len(record.seq[lsc_feature.location.start:lsc_feature.location.end]) if lsc_feature else 0\n        ssc_length = len(record.seq[ssc_feature.location.start:ssc_feature.location.end]) if ssc_feature else 0\n        \n        # Calculate IR length\n        ir_length = (genome_length - lsc_length - ssc_length) // 2\n\n        # Calculate GC content\n        total_gc = calculate_gc(record.seq)\n        lsc_gc = calculate_gc(record.seq[lsc_feature.location.start:lsc_feature.location.end]) if lsc_feature else 0\n        ssc_gc = calculate_gc(record.seq[ssc_feature.location.start:ssc_feature.location.end]) if ssc_feature else 0\n\n        # IR = everything except LSC and SSC\n        if lsc_feature and ssc_feature:\n            ir_seq = (\n                record.seq[:lsc_feature.location.start] +\n                record.seq[lsc_feature.location.end:ssc_feature.location.start] +\n                record.seq[ssc_feature.location.end:]\n            )\n            ir_gc = calculate_gc(ir_seq)\n        else:\n            ir_gc = 0\n        \n        # Extract sequences for tRNA, rRNA, CDS\n        tRNA_seq = rRNA_seq = CDS_seq = ""\n\n        for feature in record.features:\n            parts = []\n            if hasattr(feature.location, "parts"):\n                parts = feature.location.parts\n            else:\n                parts = [feature.location]\n\n            if feature.type == \'CDS\':\n                for part in parts:\n                    CDS_seq += part.extract(record.seq)\n            elif feature.type == \'tRNA\':\n                for part in parts:\n                    tRNA_seq += part.extract(record.seq)\n            elif feature.type == \'rRNA\':\n                for part in parts:\n                    rRNA_seq += part.extract(record.seq)\n\n        # GC content for gene groups\n        tRNA_gc = calculate_gc(tRNA_seq)\n        rRNA_gc = calculate_gc(rRNA_seq)\n        CDS_gc = calculate_gc(CDS_seq)\n        \n        # Store results as NUMBERS (not formatted strings)\n        results.append([\n            species, genome_length, lsc_length, ssc_length, ir_length, \n            total_gc, lsc_gc, ssc_gc, ir_gc, \n            tRNA_gc, rRNA_gc, CDS_gc, accession_number\n        ])\n\n# Create output table with new column structure\ndf = pd.DataFrame(results, columns=[\n    "Species", "Complete", "LSC", "SSC", "IR",\n    "Complete_GC", "LSC_GC", "SSC_GC", "IR_GC",\n    "tRNA", "rRNA", "CDS", "Accession Number"\n])\n\n# Save to Excel\noutput_file = \'genome_analysis_publication_quality.xlsx\'\ndf.to_excel(output_file, index=False, engine=\'openpyxl\')\n\n# Apply publication-quality formatting\nwb = load_workbook(output_file)\nws = wb.active\n\n# Define styles\nheader_font = Font(name=\'Arial\', size=11, bold=True, color=\'FFFFFF\')\nsubheader_font = Font(name=\'Arial\', size=10, bold=True, color=\'FFFFFF\')\nheader_fill = PatternFill(start_color=\'4472C4\', end_color=\'4472C4\', fill_type=\'solid\')\nheader_alignment = Alignment(horizontal=\'center\', vertical=\'center\', wrap_text=True)\n\ncell_font = Font(name=\'Arial\', size=10)\nspecies_font = Font(name=\'Arial\', size=10, italic=True)\ncell_alignment = Alignment(horizontal=\'center\', vertical=\'center\')\nspecies_alignment = Alignment(horizontal=\'left\', vertical=\'center\')\n\nthin_border = Border(\n    left=Side(style=\'thin\', color=\'000000\'),\n    right=Side(style=\'thin\', color=\'000000\'),\n    top=Side(style=\'thin\', color=\'000000\'),\n    bottom=Side(style=\'thin\', color=\'000000\')\n)\n\n# Insert a new row at the top for main headers\nws.insert_rows(1)\n\n# Merge cells for main headers\nws.merge_cells(\'A1:A2\')  # Species\nws.merge_cells(\'B1:E1\')  # Genome Length (bp)\nws.merge_cells(\'F1:I1\')  # GC (%)\nws.merge_cells(\'J1:L1\')  # GC (%)\nws.merge_cells(\'M1:M2\')  # Accession Number\n\n# Set main headers (row 1)\nws[\'A1\'] = \'Species\'\nws[\'B1\'] = \'Genome Length (bp)\'\nws[\'F1\'] = \'GC (%)\'\nws[\'J1\'] = \'GC (%)\'\nws[\'M1\'] = \'Accession Number\'\n\n# Set subheaders (row 2)\nws[\'B2\'] = \'Complete\'\nws[\'C2\'] = \'LSC\'\nws[\'D2\'] = \'SSC\'\nws[\'E2\'] = \'IR\'\nws[\'F2\'] = \'Complete\'\nws[\'G2\'] = \'LSC\'\nws[\'H2\'] = \'SSC\'\nws[\'I2\'] = \'IR\'\nws[\'J2\'] = \'tRNA\'\nws[\'K2\'] = \'rRNA\'\nws[\'L2\'] = \'CDS\'\n\n# Format all header cells\nfor row in [1, 2]:\n    for col in range(1, 14):\n        cell = ws.cell(row=row, column=col)\n        cell.font = header_font if row == 1 else subheader_font\n        cell.fill = header_fill\n        cell.alignment = header_alignment\n        cell.border = thin_border\n\n# Format data cells (starting from row 3)\nfor row_num in range(3, len(df) + 3):\n    for col_num in range(1, 14):\n        cell = ws.cell(row=row_num, column=col_num)\n        cell.border = thin_border\n        \n        # Species column - italic and left-aligned\n        if col_num == 1:\n            cell.font = species_font\n            cell.alignment = species_alignment\n        # Genome length columns (B-E: Complete, LSC, SSC, IR)\n        elif col_num in [2, 3, 4, 5]:\n            cell.font = cell_font\n            cell.alignment = Alignment(horizontal=\'right\', vertical=\'center\')\n            cell.number_format = \'#,##0\'\n        # GC percentage columns (F-L)\n        elif col_num in [6, 7, 8, 9, 10, 11, 12]:\n            cell.font = cell_font\n            cell.alignment = cell_alignment\n            cell.number_format = \'0.00\'\n        # Accession number\n        else:\n            cell.font = cell_font\n            cell.alignment = cell_alignment\n\n# Adjust column widths\ncolumn_widths = {\n    \'A\': 35,  # Species\n    \'B\': 12,  # Complete\n    \'C\': 12,  # LSC\n    \'D\': 12,  # SSC\n    \'E\': 12,  # IR\n    \'F\': 12,  # Complete GC\n    \'G\': 12,  # LSC GC\n    \'H\': 12,  # SSC GC\n    \'I\': 12,  # IR GC\n    \'J\': 12,  # tRNA GC\n    \'K\': 12,  # rRNA GC\n    \'L\': 12,  # CDS GC\n    \'M\': 16   # Accession Number\n}\n\nfor col, width in column_widths.items():\n    ws.column_dimensions[col].width = width\n\n# Set row heights\nws.row_dimensions[1].height = 25\nws.row_dimensions[2].height = 25\n\n# Freeze the header rows\nws.freeze_panes = \'A3\'\n\n# Add footnote\nfootnote_row = len(df) + 4\nws.merge_cells(f\'A{footnote_row}:M{footnote_row}\')\nfootnote_cell = ws.cell(row=footnote_row, column=1)\nfootnote_cell.value = (\'GC: guanine-cytosine content; LSC: large single-copy region; SSC: small single-copy region; \'\n                       \'IR: inverted repeat region; Complete: complete chloroplast genome; \'\n                       \'tRNA: transfer RNA; rRNA: ribosomal RNA; CDS: protein-coding sequences.\')\nfootnote_cell.font = Font(name=\'Arial\', size=9, italic=True)\nfootnote_cell.alignment = Alignment(horizontal=\'left\', vertical=\'top\', wrap_text=True)\nws.row_dimensions[footnote_row].height = 30\n\n# Save formatted workbook\nwb.save(output_file)\n\nprint(f"✓ Publication-quality table created: {output_file}")\nprint(f"✓ Location: {folder_path}")\nprint(f"✓ Total genomes analyzed: {len(results)}")\nprint(f"✓ Format: Two-level headers with grouped columns")\nprint(f"✓ Footnote added with abbreviation definitions")'

def run_mode_3():
    """
    Mode 3: IR Boundary Analysis
    
    This function executes the original script code for Mode 3.
    All logic and output formatting is preserved from the original script.
    
    Returns:
        None - Outputs are saved as Excel/Word files
        
    Raises:
        FileNotFoundError: If required input files are not found
        Exception: For other errors during execution
    """
    print("\n" + "="*80)
    print(f"MODE 3: IR Boundary Analysis")
    print("="*80 + "\n")
    
    exec(_MODE_3_CODE, globals())


# ============================================================================
# MODE 4: Codon Usage Analysis
# ============================================================================

_MODE_4_CODE = '#!/usr/bin/env python3\n"""\nRelative Synonymous Codon Usage (RSCU) Analysis Pipeline\n=========================================================\n\nThis script performs comprehensive codon usage analysis on GenBank files by:\n1. Extracting coding sequences (CDS) from GenBank format files\n2. Calculating Relative Synonymous Codon Usage (RSCU) values\n3. Generating individual RSCU reports for each genome\n4. Creating a merged comparative analysis across all genomes\n\nAuthor: Bioinformatics Analysis Tool\nVersion: 1.0\nDate: 2025\n\nDependencies:\n    - biopython (Bio)\n    - pandas\n    - openpyxl (for Excel file handling)\n\nUsage:\n    Place GenBank files (.gb, .gbf, .gbk) in the working directory and run:\n    python codon_usage_analysis.py\n\nOutput:\n    - Individual RSCU files: [genome_name]_RSCU.xlsx\n    - Merged analysis: Merged_RSCU_Analysis.xlsx\n"""\n\nimport os\nimport sys\nfrom pathlib import Path\nfrom typing import List, Dict, Tuple\nfrom collections import Counter, defaultdict\n\ntry:\n    from Bio import SeqIO\n    import pandas as pd\nexcept ImportError as e:\n    print(f"Error: Required package not installed: {e}")\n    print("Please install required packages using:")\n    print("pip install biopython pandas openpyxl")\n    sys.exit(1)\n\n\n# ============================================================================\n# CODON USAGE TABLE\n# ============================================================================\n# Standard genetic code: mapping of amino acids to their synonymous codons\n# Based on the universal genetic code (NCBI transl_table=1)\n\nSYNONYMOUS_CODONS = {\n    \'Ala\': [\'GCT\', \'GCC\', \'GCA\', \'GCG\'],\n    \'Arg\': [\'CGT\', \'CGC\', \'CGA\', \'CGG\', \'AGA\', \'AGG\'],\n    \'Asn\': [\'AAT\', \'AAC\'],\n    \'Asp\': [\'GAT\', \'GAC\'],\n    \'Cys\': [\'TGT\', \'TGC\'],\n    \'Gln\': [\'CAA\', \'CAG\'],\n    \'Glu\': [\'GAA\', \'GAG\'],\n    \'Gly\': [\'GGT\', \'GGC\', \'GGA\', \'GGG\'],\n    \'His\': [\'CAT\', \'CAC\'],\n    \'Ile\': [\'ATT\', \'ATC\', \'ATA\'],\n    \'Leu\': [\'TTA\', \'TTG\', \'CTT\', \'CTC\', \'CTA\', \'CTG\'],\n    \'Lys\': [\'AAA\', \'AAG\'],\n    \'Met\': [\'ATG\'],  # Start codon (non-degenerate)\n    \'Phe\': [\'TTT\', \'TTC\'],\n    \'Pro\': [\'CCT\', \'CCC\', \'CCA\', \'CCG\'],\n    \'Ser\': [\'TCT\', \'TCC\', \'TCA\', \'TCG\', \'AGT\', \'AGC\'],\n    \'Thr\': [\'ACT\', \'ACC\', \'ACA\', \'ACG\'],\n    \'Trp\': [\'TGG\'],  # Non-degenerate\n    \'Tyr\': [\'TAT\', \'TAC\'],\n    \'Val\': [\'GTT\', \'GTC\', \'GTA\', \'GTG\'],\n    \'Stop\': [\'TAA\', \'TAG\', \'TGA\']\n}\n\n# Full amino acid names for publication-quality output\nAMINO_ACID_NAMES = {\n    \'Ala\': \'Alanine\',\n    \'Arg\': \'Arginine\',\n    \'Asn\': \'Asparagine\',\n    \'Asp\': \'Aspartate\',\n    \'Cys\': \'Cysteine\',\n    \'Gln\': \'Glutamine\',\n    \'Glu\': \'Glutamate\',\n    \'Gly\': \'Glycine\',\n    \'His\': \'Histidine\',\n    \'Ile\': \'Isoleucine\',\n    \'Leu\': \'Leucine\',\n    \'Lys\': \'Lysine\',\n    \'Met\': \'Methionine\',\n    \'Phe\': \'Phenylalanine\',\n    \'Pro\': \'Proline\',\n    \'Ser\': \'Serine\',\n    \'Thr\': \'Threonine\',\n    \'Trp\': \'Tryptophan\',\n    \'Tyr\': \'Tyrosine\',\n    \'Val\': \'Valine\',\n    \'Stop\': \'Stop\'\n}\n\n# Define the order of amino acids for publication (alphabetical by 3-letter code)\nAA_ORDER = [\'Ala\', \'Arg\', \'Asn\', \'Asp\', \'Cys\', \'Gln\', \'Glu\', \'Gly\', \'His\', \n            \'Ile\', \'Leu\', \'Lys\', \'Met\', \'Phe\', \'Pro\', \'Ser\', \'Thr\', \'Trp\', \n            \'Tyr\', \'Val\', \'Stop\']\n\n\n# ============================================================================\n# CODON EXTRACTION AND COUNTING\n# ============================================================================\n\ndef extract_coding_sequences(genbank_file: str) -> List[str]:\n    """\n    Extract all coding sequences (CDS) from a GenBank file.\n    \n    Parameters:\n    -----------\n    genbank_file : str\n        Path to the GenBank format file\n        \n    Returns:\n    --------\n    List[str]\n        List of coding sequences as uppercase strings\n        \n    Raises:\n    -------\n    FileNotFoundError\n        If the GenBank file doesn\'t exist\n    ValueError\n        If the file cannot be parsed as GenBank format\n    """\n    try:\n        genome_record = SeqIO.read(genbank_file, "genbank")\n    except FileNotFoundError:\n        raise FileNotFoundError(f"GenBank file not found: {genbank_file}")\n    except Exception as e:\n        raise ValueError(f"Error parsing GenBank file {genbank_file}: {e}")\n    \n    coding_sequences = []\n    cds_count = 0\n    \n    # Iterate through all features in the genome\n    for feature in genome_record.features:\n        if feature.type == "CDS":\n            cds_count += 1\n            # Extract the sequence and remove any whitespace\n            seq = str(feature.extract(genome_record.seq))\n            seq = seq.replace("\\n", "").replace(" ", "").upper()\n            coding_sequences.append(seq)\n    \n    print(f"  - Extracted {cds_count} coding sequences")\n    return coding_sequences\n\n\ndef count_codons(coding_sequences: List[str]) -> Tuple[Counter, List[str]]:\n    """\n    Count the occurrence of each codon across all coding sequences.\n    \n    Parameters:\n    -----------\n    coding_sequences : List[str]\n        List of coding sequences\n        \n    Returns:\n    --------\n    Tuple[Counter, List[str]]\n        Tuple of (codon counts, list of unusual/ambiguous codons found)\n        \n    Notes:\n    ------\n    - Only complete codons (3 nucleotides) are counted\n    - Partial codons at sequence ends are ignored\n    - Detects ambiguous nucleotides (N, R, Y, etc.)\n    - Detects non-standard nucleotides\n    """\n    # Valid nucleotides in standard genetic code\n    valid_nucleotides = set(\'ATCG\')\n    \n    # Concatenate all CDS into a single sequence\n    all_cds_sequence = "".join(coding_sequences)\n    \n    # Count codons in triplets and detect unusual ones\n    codon_counts = Counter()\n    unusual_codons = []\n    \n    for i in range(0, len(all_cds_sequence), 3):\n        codon = all_cds_sequence[i:i+3]\n        \n        # Ensure complete codon\n        if len(codon) == 3:\n            codon_counts[codon] += 1\n            \n            # Check for unusual nucleotides\n            codon_nucleotides = set(codon)\n            if not codon_nucleotides.issubset(valid_nucleotides):\n                if codon not in unusual_codons:\n                    unusual_codons.append(codon)\n    \n    total_codons = sum(codon_counts.values())\n    print(f"  - Total codons counted: {total_codons:,}")\n    \n    if unusual_codons:\n        print(f"  ⚠ WARNING: Found {len(unusual_codons)} unusual codon(s): {\', \'.join(unusual_codons[:10])}")\n        if len(unusual_codons) > 10:\n            print(f"           (and {len(unusual_codons) - 10} more...)")\n    \n    return codon_counts, unusual_codons\n\n\n# ============================================================================\n# RSCU CALCULATION\n# ============================================================================\n\ndef calculate_rscu(codon_counts: Counter, \n                   synonymous_codons: Dict[str, List[str]],\n                   unusual_codons: List[str] = None) -> Tuple[pd.DataFrame, pd.DataFrame]:\n    """\n    Calculate Relative Synonymous Codon Usage (RSCU) values.\n    \n    RSCU is defined as the ratio of the observed frequency of a codon to the\n    expected frequency if all synonymous codons for an amino acid were used\n    equally.\n    \n    RSCU = (Observed codon count) / (Expected codon count)\n    \n    Where:\n        Expected count = (Total AA count) / (Number of synonymous codons)\n    \n    RSCU values interpretation:\n        - RSCU > 1.0: Codon is used more frequently than expected\n        - RSCU = 1.0: Codon is used at the expected frequency\n        - RSCU < 1.0: Codon is used less frequently than expected\n    \n    Parameters:\n    -----------\n    codon_counts : Counter\n        Dictionary of codon counts\n    synonymous_codons : Dict[str, List[str]]\n        Mapping of amino acids to their synonymous codons\n    unusual_codons : List[str], optional\n        List of unusual/ambiguous codons detected\n        \n    Returns:\n    --------\n    Tuple[pd.DataFrame, pd.DataFrame]\n        Tuple of (RSCU DataFrame, unusual codons DataFrame)\n    """\n    # Get all standard codons\n    all_standard_codons = set()\n    for codons in synonymous_codons.values():\n        all_standard_codons.update(codons)\n    \n    # Calculate total counts for each amino acid\n    aa_totals = defaultdict(int)\n    for aa, codons in synonymous_codons.items():\n        for codon in codons:\n            aa_totals[aa] += codon_counts[codon]\n    \n    # Calculate RSCU for each codon in publication order\n    rscu_data = []\n    for aa in AA_ORDER:\n        codons = synonymous_codons[aa]\n        num_synonymous = len(codons)  # Degeneracy of amino acid\n        full_name = AMINO_ACID_NAMES[aa]\n        \n        for idx, codon in enumerate(codons):\n            observed_count = codon_counts[codon]\n            \n            # Calculate expected count (uniform distribution)\n            expected_count = aa_totals[aa] / num_synonymous if aa_totals[aa] > 0 else 0\n            \n            # Calculate RSCU\n            if expected_count > 0:\n                rscu = observed_count / expected_count\n            else:\n                rscu = 0.0\n            \n            # For publication format: show AA name only for first codon\n            if idx == 0:\n                rscu_data.append({\n                    \'AA\': aa,\n                    \'Amino_Acid\': full_name,\n                    \'Codon\': codon,\n                    \'Count\': observed_count,\n                    \'RSCU\': round(rscu, 4)\n                })\n            else:\n                rscu_data.append({\n                    \'AA\': \'\',  # Empty for subsequent codons\n                    \'Amino_Acid\': \'\',\n                    \'Codon\': codon,\n                    \'Count\': observed_count,\n                    \'RSCU\': round(rscu, 4)\n                })\n    \n    # Create DataFrame\n    df_rscu = pd.DataFrame(rscu_data)\n    \n    # Handle unusual codons (those not in standard genetic code)\n    unusual_data = []\n    if unusual_codons:\n        for codon in unusual_codons:\n            if codon not in all_standard_codons:\n                unusual_data.append({\n                    \'Codon\': codon,\n                    \'Count\': codon_counts[codon],\n                    \'Note\': \'Contains ambiguous/non-standard nucleotides\'\n                })\n    \n    # Also check for observed codons not in standard list\n    for codon, count in codon_counts.items():\n        if codon not in all_standard_codons and codon not in [u[\'Codon\'] for u in unusual_data]:\n            unusual_data.append({\n                \'Codon\': codon,\n                \'Count\': count,\n                \'Note\': \'Not in standard genetic code table\'\n            })\n    \n    df_unusual = pd.DataFrame(unusual_data) if unusual_data else pd.DataFrame()\n    \n    if not df_unusual.empty:\n        total_unusual = df_unusual[\'Count\'].sum()\n        print(f"  ⚠ WARNING: {len(df_unusual)} unusual codon type(s) with {total_unusual:,} total occurrences")\n    \n    return df_rscu, df_unusual\n\n\n# ============================================================================\n# FILE PROCESSING\n# ============================================================================\n\ndef process_single_genbank_file(file_path: str) -> Tuple[str, pd.DataFrame]:\n    """\n    Process a single GenBank file and calculate RSCU values.\n    \n    Parameters:\n    -----------\n    file_path : str\n        Path to the GenBank file\n        \n    Returns:\n    --------\n    Tuple[str, pd.DataFrame]\n        Tuple of (output filename, RSCU DataFrame)\n    """\n    print(f"\\nProcessing: {file_path}")\n    \n    # Extract coding sequences\n    coding_sequences = extract_coding_sequences(file_path)\n    \n    if not coding_sequences:\n        print(f"  WARNING: No coding sequences found in {file_path}")\n        return None, None\n    \n    # Count codons and detect unusual ones\n    codon_counts, unusual_codons = count_codons(coding_sequences)\n    \n    # Calculate RSCU\n    df_rscu, df_unusual = calculate_rscu(codon_counts, SYNONYMOUS_CODONS, unusual_codons)\n    \n    # Generate output filename\n    base_name = Path(file_path).stem\n    output_file = f"{base_name}_RSCU.xlsx"\n    \n    # Save individual RSCU file with multiple sheets\n    with pd.ExcelWriter(output_file, engine=\'openpyxl\') as writer:\n        # Main RSCU analysis (all 64 standard codons)\n        df_rscu.to_excel(writer, sheet_name=\'RSCU_Analysis\', index=False)\n        \n        # If unusual codons found, add them to a separate sheet\n        if not df_unusual.empty:\n            df_unusual.to_excel(writer, sheet_name=\'Unusual_Codons\', index=False)\n            print(f"  ⚠ Unusual codons saved in separate sheet")\n        \n        # Add summary statistics sheet\n        summary_data = {\n            \'Metric\': [\n                \'Total CDS sequences\',\n                \'Total codons analyzed\',\n                \'Standard codons\',\n                \'Unusual codons detected\',\n                \'Unusual codon occurrences\'\n            ],\n            \'Value\': [\n                len(coding_sequences),\n                sum(codon_counts.values()),\n                64,\n                len(df_unusual),\n                df_unusual[\'Count\'].sum() if not df_unusual.empty else 0\n            ]\n        }\n        df_summary = pd.DataFrame(summary_data)\n        df_summary.to_excel(writer, sheet_name=\'Summary\', index=False)\n    \n    print(f"  ✓ Saved: {output_file}")\n    \n    return output_file, df_rscu\n\n\ndef find_genbank_files(directory: str = None) -> List[str]:\n    """\n    Find all GenBank files in the specified directory.\n    \n    Parameters:\n    -----------\n    directory : str, optional\n        Directory to search (default: current working directory)\n        \n    Returns:\n    --------\n    List[str]\n        List of GenBank file paths\n    """\n    if directory is None:\n        directory = os.getcwd()\n    \n    # Supported GenBank file extensions\n    genbank_extensions = (\'.gb\', \'.gbf\', \'.gbk\', \'.genbank\')\n    \n    genbank_files = [\n        os.path.join(directory, f) \n        for f in os.listdir(directory) \n        if f.lower().endswith(genbank_extensions)\n    ]\n    \n    return sorted(genbank_files)\n\n\n# ============================================================================\n# MERGE RSCU FILES\n# ============================================================================\n\ndef merge_rscu_files(rscu_files: List[str], output_file: str = \'Merged_RSCU_Analysis.xlsx\'):\n    """\n    Merge individual RSCU files into a single comparative analysis file.\n    \n    Creates a merged Excel file where each column represents RSCU values from\n    a different genome, allowing for easy comparison of codon usage patterns.\n    The amino acid cells are vertically merged to span all synonymous codons.\n    \n    Parameters:\n    -----------\n    rscu_files : List[str]\n        List of RSCU Excel file paths to merge\n    output_file : str\n        Name of the output merged file\n    """\n    print(f"\\n{\'=\'*70}")\n    print("MERGING RSCU FILES")\n    print(f"{\'=\'*70}")\n    \n    if not rscu_files:\n        print("No RSCU files to merge.")\n        return\n    \n    # Read all RSCU files and collect data\n    all_data = []\n    genome_names = []\n    \n    for filename in rscu_files:\n        print(f"  - Adding: {filename}")\n        \n        try:\n            # Read the RSCU file\n            data = pd.read_excel(filename, sheet_name=\'RSCU_Analysis\')\n            \n            # Get the genome name from filename\n            genome_name = Path(filename).stem.replace(\'_RSCU\', \'\')\n            genome_names.append(genome_name)\n            \n            # Store the data\n            all_data.append(data)\n            \n        except Exception as e:\n            print(f"  WARNING: Error reading {filename}: {e}")\n            continue\n    \n    if not all_data:\n        print("  ERROR: No data to merge.")\n        return\n    \n    # Create the merged structure\n    # Start with Codon column from first file\n    base_data = all_data[0][[\'AA\', \'Amino_Acid\', \'Codon\']].copy()\n    \n    # Keep amino acid name only on first occurrence\n    display_amino_acid = []\n    for idx, row in base_data.iterrows():\n        if row[\'AA\']:  # Non-empty AA code means first codon of new amino acid\n            display_amino_acid.append(row[\'Amino_Acid\'])\n        else:\n            display_amino_acid.append(\'\')\n    \n    # Build the final merged dataframe\n    merged_data = pd.DataFrame()\n    merged_data[\'Amino_Acid\'] = display_amino_acid\n    merged_data[\'Codon\'] = base_data[\'Codon\']\n    \n    # Add RSCU columns from each genome\n    for genome_name, data in zip(genome_names, all_data):\n        merged_data[genome_name] = data[\'RSCU\'].values\n    \n    # Save merged file with proper formatting\n    with pd.ExcelWriter(output_file, engine=\'openpyxl\') as writer:\n        merged_data.to_excel(writer, sheet_name=\'Merged_RSCU\', index=False)\n        \n        # Get the worksheet to apply formatting\n        workbook = writer.book\n        worksheet = writer.sheets[\'Merged_RSCU\']\n        \n        # Apply formatting for publication quality\n        from openpyxl.styles import Font, Alignment, PatternFill, Border, Side\n        \n        # Header formatting\n        header_fill = PatternFill(start_color=\'366092\', end_color=\'366092\', fill_type=\'solid\')\n        header_font = Font(bold=True, color=\'FFFFFF\', size=11)\n        \n        for cell in worksheet[1]:\n            cell.fill = header_fill\n            cell.font = header_font\n            cell.alignment = Alignment(horizontal=\'center\', vertical=\'center\')\n        \n        # Make species name headers italic (columns C onwards, excluding "Amino_Acid" and "Codon")\n        for col_idx in range(3, len(genome_names) + 3):\n            header_cell = worksheet.cell(row=1, column=col_idx)\n            header_cell.font = Font(bold=True, italic=True, color=\'FFFFFF\', size=11)\n        \n        # Data formatting\n        thin_border = Border(\n            left=Side(style=\'thin\'),\n            right=Side(style=\'thin\'),\n            top=Side(style=\'thin\'),\n            bottom=Side(style=\'thin\')\n        )\n        \n        # Track amino acid groups for merging cells\n        merge_groups = []\n        current_aa = None\n        start_row = None\n        \n        # First pass: identify merge ranges and format cells\n        \n        # Format data rows\n        for row_idx, row in enumerate(worksheet.iter_rows(min_row=2, max_row=worksheet.max_row), start=2):\n            amino_acid_value = row[0].value\n            \n            # Track amino acid groups for cell merging\n            if amino_acid_value and str(amino_acid_value).strip():\n                # Save previous group if exists\n                if current_aa is not None and start_row is not None:\n                    end_row = row_idx - 1\n                    if end_row > start_row:  # Only merge if more than one row\n                        merge_groups.append((start_row, end_row))\n                \n                # Start new group\n                current_aa = amino_acid_value\n                start_row = row_idx\n            \n            # Format all cells in the row\n            for col_idx, cell in enumerate(row):\n                cell.border = thin_border\n                \n                # First column (Amino_Acid): left align and make bold + italic\n                if col_idx == 0:\n                    cell.alignment = Alignment(horizontal=\'center\', vertical=\'center\')\n                    if cell.value and str(cell.value).strip():\n                        cell.font = Font(bold=True, italic=True, size=10)\n                \n                # Second column (Codon): center align\n                elif col_idx == 1:\n                    cell.alignment = Alignment(horizontal=\'center\', vertical=\'center\')\n                \n                # RSCU value columns: format to 4 decimal places (NO italic for numbers)\n                else:\n                    cell.alignment = Alignment(horizontal=\'center\', vertical=\'center\')\n                    if cell.value is not None:\n                        try:\n                            cell.number_format = \'0.0000\'\n                            # Don\'t apply italic to RSCU numbers\n                        except:\n                            pass\n        \n        # Don\'t forget the last group\n        if current_aa is not None and start_row is not None:\n            end_row = worksheet.max_row\n            if end_row > start_row:  # Only merge if more than one row\n                merge_groups.append((start_row, end_row))\n        \n        # Second pass: merge cells for amino acids with multiple codons\n        for start_row, end_row in merge_groups:\n            # Merge cells in the Amino_Acid column (column A)\n            worksheet.merge_cells(f\'A{start_row}:A{end_row}\')\n            \n            # Apply formatting to merged cell\n            merged_cell = worksheet[f\'A{start_row}\']\n            merged_cell.alignment = Alignment(horizontal=\'center\', vertical=\'center\')\n            merged_cell.font = Font(bold=True, italic=True, size=10)\n            merged_cell.border = thin_border\n        \n        # Adjust column widths\n        worksheet.column_dimensions[\'A\'].width = 15  # Amino_Acid\n        worksheet.column_dimensions[\'B\'].width = 8   # Codon\n        \n        # Set width for genome columns (make them wider for species names)\n        for col_idx in range(3, len(genome_names) + 3):\n            col_letter = worksheet.cell(row=1, column=col_idx).column_letter\n            worksheet.column_dimensions[col_letter].width = 14\n        \n        # Freeze panes (freeze first row and first two columns)\n        worksheet.freeze_panes = \'C2\'\n    \n    print(f"\\n  ✓ Merged analysis saved: {output_file}")\n    print(f"  - Total genomes compared: {len(genome_names)}")\n    print(f"  - Total codons: {len(merged_data)}")\n    print(f"  - Format: Publication-ready with vertically merged amino acid cells")\n    print(f"  - Species names formatted in italic")\n\n\n# ============================================================================\n# MAIN PIPELINE\n# ============================================================================\n\ndef main():\n    """\n    Main pipeline execution function.\n    \n    Workflow:\n    1. Find all GenBank files in working directory\n    2. Process each file to calculate RSCU\n    3. Merge all RSCU files into comparative analysis\n    """\n    print(f"\\n{\'=\'*70}")\n    print("CODON USAGE ANALYSIS PIPELINE")\n    print(f"{\'=\'*70}")\n    \n    # Get working directory\n    working_dir = os.getcwd()\n    print(f"\\nWorking directory: {working_dir}")\n    \n    # Find GenBank files\n    genbank_files = find_genbank_files(working_dir)\n    \n    if not genbank_files:\n        print("\\n❌ ERROR: No GenBank files found!")\n        print("Please place GenBank files (.gb, .gbf, .gbk) in the working directory.")\n        return\n    \n    print(f"\\nFound {len(genbank_files)} GenBank file(s):")\n    for gf in genbank_files:\n        print(f"  - {os.path.basename(gf)}")\n    \n    # Process each GenBank file\n    print(f"\\n{\'=\'*70}")\n    print("CALCULATING RSCU VALUES")\n    print(f"{\'=\'*70}")\n    \n    rscu_files = []\n    for gb_file in genbank_files:\n        try:\n            output_file, _ = process_single_genbank_file(gb_file)\n            if output_file:\n                rscu_files.append(output_file)\n        except Exception as e:\n            print(f"  ❌ ERROR processing {gb_file}: {e}")\n            continue\n    \n    # Merge RSCU files\n    if rscu_files:\n        merge_rscu_files(rscu_files)\n    \n    # Summary\n    print(f"\\n{\'=\'*70}")\n    print("ANALYSIS COMPLETE")\n    print(f"{\'=\'*70}")\n    print(f"✓ Successfully processed: {len(rscu_files)} genome(s)")\n    print(f"✓ Individual RSCU files: {len(rscu_files)}")\n    print(f"✓ Merged analysis file: Merged_RSCU_Analysis.xlsx")\n    print(f"\\nAll output files saved in: {working_dir}")\n    print(f"{\'=\'*70}\\n")\n\n\n# ============================================================================\n# SCRIPT ENTRY POINT\n# ============================================================================\n\nif True:\n    try:\n        main()\n    except KeyboardInterrupt:\n        print("\\n\\n⚠ Analysis interrupted by user.")\n        sys.exit(0)\n    except Exception as e:\n        print(f"\\n\\n❌ FATAL ERROR: {e}")\n        import traceback\n        traceback.print_exc()\n        sys.exit(1)'

def run_mode_4():
    """
    Mode 4: Codon Usage Analysis
    
    This function executes the original script code for Mode 4.
    All logic and output formatting is preserved from the original script.
    
    Returns:
        None - Outputs are saved as Excel/Word files
        
    Raises:
        FileNotFoundError: If required input files are not found
        Exception: For other errors during execution
    """
    print("\n" + "="*80)
    print(f"MODE 4: Codon Usage Analysis")
    print("="*80 + "\n")
    
    exec(_MODE_4_CODE, globals())


# ============================================================================
# MODE 5: Amino Acid Analysis
# ============================================================================

_MODE_5_CODE = '#!/usr/bin/env python3\n"""\nAmino Acid Composition Analysis Pipeline\n=========================================\n\nThis script performs comprehensive amino acid composition analysis on GenBank files by:\n1. Extracting and translating coding sequences (CDS) from GenBank format files\n2. Calculating amino acid composition percentages\n3. Generating individual composition reports for each genome\n4. Creating a merged comparative analysis across all genomes\n\nAuthor: Bioinformatics Analysis Tool\nVersion: 1.0\nDate: 2025\n\nDependencies:\n    - biopython (Bio)\n    - pandas\n    - openpyxl (for Excel file handling)\n\nUsage:\n    Place GenBank files (.gb, .gbf, .gbk) in the working directory and run:\n    python amino_acid_analysis.py\n\nOutput:\n    - Individual composition files: [genome_name]_AminoAcid.xlsx\n    - Merged analysis: Merged_AminoAcid_Analysis.xlsx\n"""\n\nimport os\nimport sys\nfrom pathlib import Path\nfrom typing import List, Dict, Tuple\nfrom collections import Counter\n\ntry:\n    from Bio import SeqIO\n    from Bio.Seq import Seq\n    from Bio.SeqUtils import ProtParam\n    import pandas as pd\nexcept ImportError as e:\n    print(f"Error: Required package not installed: {e}")\n    print("Please install required packages using:")\n    print("pip install biopython pandas openpyxl")\n    sys.exit(1)\n\n\n# ============================================================================\n# AMINO ACID INFORMATION\n# ============================================================================\n\n# Full amino acid names mapping\nAMINO_ACID_NAMES = {\n    \'A\': \'Alanine\',\n    \'R\': \'Arginine\',\n    \'N\': \'Asparagine\',\n    \'D\': \'Aspartate\',\n    \'C\': \'Cysteine\',\n    \'Q\': \'Glutamine\',\n    \'E\': \'Glutamate\',\n    \'G\': \'Glycine\',\n    \'H\': \'Histidine\',\n    \'I\': \'Isoleucine\',\n    \'L\': \'Leucine\',\n    \'K\': \'Lysine\',\n    \'M\': \'Methionine\',\n    \'F\': \'Phenylalanine\',\n    \'P\': \'Proline\',\n    \'S\': \'Serine\',\n    \'T\': \'Threonine\',\n    \'W\': \'Tryptophan\',\n    \'Y\': \'Tyrosine\',\n    \'V\': \'Valine\'\n}\n\n# Amino acid order for publication (alphabetical)\nAA_ORDER = [\'A\', \'R\', \'N\', \'D\', \'C\', \'Q\', \'E\', \'G\', \'H\', \'I\', \n            \'L\', \'K\', \'M\', \'F\', \'P\', \'S\', \'T\', \'W\', \'Y\', \'V\']\n\n\n# ============================================================================\n# SEQUENCE EXTRACTION AND TRANSLATION\n# ============================================================================\n\ndef get_organism_name(genbank_file: str) -> str:\n    """\n    Extract organism name from GenBank file annotations.\n    \n    Parameters:\n    -----------\n    genbank_file : str\n        Path to the GenBank file\n        \n    Returns:\n    --------\n    str\n        Organism name with spaces replaced by underscores\n    """\n    try:\n        record = SeqIO.read(genbank_file, "genbank")\n        organism = record.annotations.get("organism", "Unknown")\n        # Replace spaces with underscores for file naming\n        return organism.replace(" ", "_")\n    except Exception as e:\n        print(f"  WARNING: Error reading organism name: {e}")\n        return "Unknown"\n\n\ndef extract_and_translate_cds(genbank_file: str) -> Tuple[str, int]:\n    """\n    Extract all CDS features and translate them to amino acid sequences.\n    \n    Parameters:\n    -----------\n    genbank_file : str\n        Path to the GenBank file\n        \n    Returns:\n    --------\n    Tuple[str, int]\n        Combined amino acid sequence and number of CDS features processed\n        \n    Notes:\n    ------\n    - Sequences are translated using the standard genetic code\n    - Translation stops at the first stop codon\n    - Stop codons are excluded from the final sequence\n    """\n    all_amino_acid_sequences = []\n    cds_count = 0\n    \n    try:\n        record = SeqIO.read(genbank_file, "genbank")\n        \n        for feature in record.features:\n            if feature.type == "CDS":\n                try:\n                    # Extract CDS sequence\n                    cds_seq = feature.extract(record.seq)\n                    \n                    # Translate to amino acids (stop at first stop codon)\n                    amino_acid_sequence = cds_seq.translate(to_stop=True)\n                    \n                    all_amino_acid_sequences.append(str(amino_acid_sequence))\n                    cds_count += 1\n                    \n                except Exception as e:\n                    print(f"  WARNING: Error translating CDS: {e}")\n                    continue\n        \n        print(f"  - Extracted and translated {cds_count} coding sequences")\n        \n    except Exception as e:\n        print(f"  ERROR: Failed to process file: {e}")\n        return "", 0\n    \n    # Combine all amino acid sequences\n    combined_sequence = "".join(all_amino_acid_sequences)\n    \n    return combined_sequence, cds_count\n\n\n# ============================================================================\n# AMINO ACID COMPOSITION ANALYSIS\n# ============================================================================\n\ndef analyze_amino_acid_composition(amino_acid_sequence: str) -> pd.DataFrame:\n    """\n    Analyze amino acid composition and calculate percentages.\n    \n    Uses Biopython\'s ProteinAnalysis module to calculate the percentage\n    composition of each amino acid in the protein sequence.\n    \n    Parameters:\n    -----------\n    amino_acid_sequence : str\n        Combined amino acid sequence from all CDS\n        \n    Returns:\n    --------\n    pd.DataFrame\n        DataFrame with columns: AA_Code, Amino_Acid, Percentage\n        \n    Notes:\n    ------\n    - Percentages represent the fraction of each amino acid\n    - Values are multiplied by 100 for percentage format\n    - Results are sorted alphabetically by amino acid code\n    """\n    if not amino_acid_sequence:\n        print("  WARNING: Empty amino acid sequence")\n        return pd.DataFrame()\n    \n    # Use Biopython\'s ProteinAnalysis\n    protein_analysis = ProtParam.ProteinAnalysis(amino_acid_sequence)\n    composition = protein_analysis.amino_acids_percent\n    \n    # Convert to structured data\n    composition_data = []\n    for aa_code in AA_ORDER:\n        if aa_code in composition:\n            percentage = composition[aa_code]  # Already in percentage (0-100)\n            composition_data.append({\n                \'AA_Code\': aa_code,\n                \'Amino_Acid\': AMINO_ACID_NAMES[aa_code],\n                \'Percentage\': round(percentage, 4)\n            })\n    \n    df = pd.DataFrame(composition_data)\n    \n    total_aa = len(amino_acid_sequence)\n    print(f"  - Total amino acids analyzed: {total_aa:,}")\n    \n    return df\n\n\n# ============================================================================\n# FILE PROCESSING\n# ============================================================================\n\ndef process_single_genbank_file(file_path: str) -> Tuple[str, pd.DataFrame]:\n    """\n    Process a single GenBank file and calculate amino acid composition.\n    \n    Parameters:\n    -----------\n    file_path : str\n        Path to the GenBank file\n        \n    Returns:\n    --------\n    Tuple[str, pd.DataFrame]\n        Tuple of (output filename, composition DataFrame)\n    """\n    print(f"\\nProcessing: {file_path}")\n    \n    # Get organism name\n    organism_name = get_organism_name(file_path)\n    print(f"  - Organism: {organism_name}")\n    \n    # Extract and translate CDS\n    amino_acid_sequence, cds_count = extract_and_translate_cds(file_path)\n    \n    if not amino_acid_sequence:\n        print(f"  WARNING: No amino acid sequences found in {file_path}")\n        return None, None\n    \n    # Analyze composition\n    df_composition = analyze_amino_acid_composition(amino_acid_sequence)\n    \n    if df_composition.empty:\n        return None, None\n    \n    # Generate output filename\n    base_name = Path(file_path).stem\n    output_file = f"{base_name}_AminoAcid.xlsx"\n    \n    # Save individual composition file\n    with pd.ExcelWriter(output_file, engine=\'openpyxl\') as writer:\n        # Main composition sheet\n        df_composition.to_excel(writer, sheet_name=\'AA_Composition\', index=False)\n        \n        # Summary statistics sheet\n        summary_data = {\n            \'Metric\': [\n                \'Organism\',\n                \'Total CDS sequences\',\n                \'Total amino acids\',\n                \'Number of AA types\'\n            ],\n            \'Value\': [\n                organism_name.replace(\'_\', \' \'),\n                cds_count,\n                len(amino_acid_sequence),\n                len(df_composition)\n            ]\n        }\n        df_summary = pd.DataFrame(summary_data)\n        df_summary.to_excel(writer, sheet_name=\'Summary\', index=False)\n    \n    print(f"  ✓ Saved: {output_file}")\n    \n    return output_file, df_composition\n\n\ndef find_genbank_files(directory: str = None) -> List[str]:\n    """\n    Find all GenBank files in the specified directory.\n    \n    Parameters:\n    -----------\n    directory : str, optional\n        Directory to search (default: current working directory)\n        \n    Returns:\n    --------\n    List[str]\n        List of GenBank file paths\n    """\n    if directory is None:\n        directory = os.getcwd()\n    \n    # Supported GenBank file extensions\n    genbank_extensions = (\'.gb\', \'.gbf\', \'.gbk\', \'.genbank\')\n    \n    genbank_files = [\n        os.path.join(directory, f) \n        for f in os.listdir(directory) \n        if f.lower().endswith(genbank_extensions)\n    ]\n    \n    return sorted(genbank_files)\n\n\n# ============================================================================\n# MERGE COMPOSITION FILES\n# ============================================================================\n\ndef merge_amino_acid_files(aa_files: List[str], output_file: str = \'Merged_AminoAcid_Analysis.xlsx\'):\n    """\n    Merge individual amino acid composition files into a single comparative analysis file.\n    \n    Creates a merged Excel file where each column represents composition percentages\n    from a different genome, with publication-quality formatting.\n    \n    Parameters:\n    -----------\n    aa_files : List[str]\n        List of amino acid composition Excel file paths to merge\n    output_file : str\n        Name of the output merged file\n    """\n    print(f"\\n{\'=\'*70}")\n    print("MERGING AMINO ACID COMPOSITION FILES")\n    print(f"{\'=\'*70}")\n    \n    if not aa_files:\n        print("No amino acid files to merge.")\n        return\n    \n    # Read all composition files and collect data\n    all_data = []\n    genome_names = []\n    \n    for filename in aa_files:\n        print(f"  - Adding: {filename}")\n        \n        try:\n            # Read the composition file\n            data = pd.read_excel(filename, sheet_name=\'AA_Composition\')\n            \n            # Get the genome name from filename\n            genome_name = Path(filename).stem.replace(\'_AminoAcid\', \'\')\n            genome_names.append(genome_name)\n            \n            # Store the data\n            all_data.append(data)\n            \n        except Exception as e:\n            print(f"  WARNING: Error reading {filename}: {e}")\n            continue\n    \n    if not all_data:\n        print("  ERROR: No data to merge.")\n        return\n    \n    # Create the merged structure\n    base_data = all_data[0][[\'AA_Code\', \'Amino_Acid\']].copy()\n    \n    # Build the final merged dataframe\n    merged_data = pd.DataFrame()\n    merged_data[\'Amino_Acid\'] = base_data[\'Amino_Acid\']\n    \n    # Add percentage columns from each genome\n    for genome_name, data in zip(genome_names, all_data):\n        merged_data[genome_name] = data[\'Percentage\'].values\n    \n    # Save merged file with proper formatting\n    with pd.ExcelWriter(output_file, engine=\'openpyxl\') as writer:\n        merged_data.to_excel(writer, sheet_name=\'Merged_AA_Composition\', index=False)\n        \n        # Get the worksheet to apply formatting\n        workbook = writer.book\n        worksheet = writer.sheets[\'Merged_AA_Composition\']\n        \n        # Apply formatting for publication quality\n        from openpyxl.styles import Font, Alignment, PatternFill, Border, Side\n        \n        # Header formatting\n        header_fill = PatternFill(start_color=\'366092\', end_color=\'366092\', fill_type=\'solid\')\n        \n        for cell in worksheet[1]:\n            cell.fill = header_fill\n            cell.font = Font(bold=True, color=\'FFFFFF\', size=11)\n            cell.alignment = Alignment(horizontal=\'center\', vertical=\'center\')\n        \n        # Make species name headers italic (columns B onwards)\n        for col_idx in range(2, len(genome_names) + 2):\n            header_cell = worksheet.cell(row=1, column=col_idx)\n            header_cell.font = Font(bold=True, italic=True, color=\'FFFFFF\', size=11)\n        \n        # Data formatting\n        thin_border = Border(\n            left=Side(style=\'thin\'),\n            right=Side(style=\'thin\'),\n            top=Side(style=\'thin\'),\n            bottom=Side(style=\'thin\')\n        )\n        \n        # Format data rows\n        for row_idx, row in enumerate(worksheet.iter_rows(min_row=2, max_row=worksheet.max_row), start=2):\n            for col_idx, cell in enumerate(row):\n                cell.border = thin_border\n                \n                # First column (Amino_Acid): bold + italic, center aligned\n                if col_idx == 0:\n                    cell.alignment = Alignment(horizontal=\'center\', vertical=\'center\')\n                    if cell.value:\n                        cell.font = Font(bold=True, italic=True, size=10)\n                \n                # Percentage columns: format to 4 decimal places, center aligned\n                else:\n                    cell.alignment = Alignment(horizontal=\'center\', vertical=\'center\')\n                    if cell.value is not None:\n                        try:\n                            cell.number_format = \'0.0000\'\n                        except:\n                            pass\n        \n        # Adjust column widths\n        worksheet.column_dimensions[\'A\'].width = 15  # Amino_Acid\n        \n        # Set width for genome columns\n        for col_idx in range(2, len(genome_names) + 2):\n            col_letter = worksheet.cell(row=1, column=col_idx).column_letter\n            worksheet.column_dimensions[col_letter].width = 14\n        \n        # Freeze panes (freeze first row and first column)\n        worksheet.freeze_panes = \'B2\'\n    \n    print(f"\\n  ✓ Merged analysis saved: {output_file}")\n    print(f"  - Total genomes compared: {len(genome_names)}")\n    print(f"  - Total amino acids: {len(merged_data)}")\n    print(f"  - Format: Publication-ready with italic species names")\n\n\n# ============================================================================\n# MAIN PIPELINE\n# ============================================================================\n\ndef main():\n    """\n    Main pipeline execution function.\n    \n    Workflow:\n    1. Find all GenBank files in working directory\n    2. Process each file to calculate amino acid composition\n    3. Merge all composition files into comparative analysis\n    """\n    print(f"\\n{\'=\'*70}")\n    print("AMINO ACID COMPOSITION ANALYSIS PIPELINE")\n    print(f"{\'=\'*70}")\n    \n    # Get working directory\n    working_dir = os.getcwd()\n    print(f"\\nWorking directory: {working_dir}")\n    \n    # Find GenBank files\n    genbank_files = find_genbank_files(working_dir)\n    \n    if not genbank_files:\n        print("\\n❌ ERROR: No GenBank files found!")\n        print("Please place GenBank files (.gb, .gbf, .gbk) in the working directory.")\n        return\n    \n    print(f"\\nFound {len(genbank_files)} GenBank file(s):")\n    for gf in genbank_files:\n        print(f"  - {os.path.basename(gf)}")\n    \n    # Process each GenBank file\n    print(f"\\n{\'=\'*70}")\n    print("CALCULATING AMINO ACID COMPOSITION")\n    print(f"{\'=\'*70}")\n    \n    aa_files = []\n    for gb_file in genbank_files:\n        try:\n            output_file, _ = process_single_genbank_file(gb_file)\n            if output_file:\n                aa_files.append(output_file)\n        except Exception as e:\n            print(f"  ❌ ERROR processing {gb_file}: {e}")\n            continue\n    \n    # Merge composition files\n    if aa_files:\n        merge_amino_acid_files(aa_files)\n    \n    # Summary\n    print(f"\\n{\'=\'*70}")\n    print("ANALYSIS COMPLETE")\n    print(f"{\'=\'*70}")\n    print(f"✓ Successfully processed: {len(aa_files)} genome(s)")\n    print(f"✓ Individual composition files: {len(aa_files)}")\n    print(f"✓ Merged analysis file: Merged_AminoAcid_Analysis.xlsx")\n    print(f"\\nAll output files saved in: {working_dir}")\n    print(f"{\'=\'*70}\\n")\n\n\n# ============================================================================\n# SCRIPT ENTRY POINT\n# ============================================================================\n\nif True:\n    try:\n        main()\n    except KeyboardInterrupt:\n        print("\\n\\n⚠ Analysis interrupted by user.")\n        sys.exit(0)\n    except Exception as e:\n        print(f"\\n\\n❌ FATAL ERROR: {e}")\n        import traceback\n        traceback.print_exc()\n        sys.exit(1)'

def run_mode_5():
    """
    Mode 5: Amino Acid Analysis
    
    This function executes the original script code for Mode 5.
    All logic and output formatting is preserved from the original script.
    
    Returns:
        None - Outputs are saved as Excel/Word files
        
    Raises:
        FileNotFoundError: If required input files are not found
        Exception: For other errors during execution
    """
    print("\n" + "="*80)
    print(f"MODE 5: Amino Acid Analysis")
    print("="*80 + "\n")
    
    exec(_MODE_5_CODE, globals())


# ============================================================================
# MODE 6: SNP Analysis
# ============================================================================

_MODE_6_CODE = '#!/usr/bin/env python3\n"""\nNucleotide Substitution Analysis Pipeline\n==========================================\n\nThis script performs comprehensive nucleotide substitution analysis on FASTA alignment files by:\n1. Comparing pairwise aligned sequences from FASTA files\n2. Identifying and counting all types of nucleotide substitutions\n3. Calculating transition (Ts) and transversion (Tv) counts and ratios\n4. Recording positions of each substitution type\n5. Generating individual Excel reports for each alignment\n6. Creating a merged comparative analysis across all alignments\n\nAuthor: Bioinformatics Analysis Tool\nVersion: 1.0\nDate: 2025\n\nDependencies:\n    - openpyxl (for Excel file handling)\n\nUsage:\n    Place FASTA alignment files (.fasta, .fa, .fna) in the working directory and run:\n    python substitution_analysis.py\n\nOutput:\n    - Individual substitution files: [alignment_name]_Substitutions.xlsx\n    - Merged analysis: Merged_Substitution_Analysis.xlsx\n\nNotes:\n    - FASTA files must contain exactly 2 sequences (reference and query)\n    - Sequences must be pre-aligned and of equal length\n    - Gaps (-) are ignored in the analysis\n"""\n\nimport os\nimport sys\nfrom pathlib import Path\nfrom typing import Dict, List, Tuple\n\ntry:\n    import openpyxl\n    from openpyxl.styles import Font, Alignment, PatternFill, Border, Side\nexcept ImportError as e:\n    print(f"Error: Required package not installed: {e}")\n    print("Please install required packages using:")\n    print("pip install openpyxl")\n    sys.exit(1)\n\n\n# ============================================================================\n# SUBSTITUTION TYPE DEFINITIONS\n# ============================================================================\n\n# All possible nucleotide substitutions\nSUBSTITUTION_TYPES = [\n    \'A_to_G\', \'G_to_A\', \'T_to_G\', \'G_to_T\',\n    \'A_to_C\', \'C_to_A\', \'C_to_T\', \'T_to_C\',\n    \'G_to_C\', \'C_to_G\', \'A_to_T\', \'T_to_A\'\n]\n\n# Transition substitutions (purine-purine or pyrimidine-pyrimidine)\nTRANSITIONS = [\'A_to_G\', \'G_to_A\', \'C_to_T\', \'T_to_C\']\n\n# Transversion substitutions (purine-pyrimidine or pyrimidine-purine)\nTRANSVERSIONS = [\'T_to_G\', \'G_to_T\', \'A_to_C\', \'C_to_A\', \n                 \'G_to_C\', \'C_to_G\', \'A_to_T\', \'T_to_A\']\n\n\n# ============================================================================\n# SEQUENCE LOADING\n# ============================================================================\n\ndef load_fasta_sequences(fasta_file: str) -> Tuple[List[str], List[str]]:\n    """\n    Load sequences from a FASTA file.\n    \n    Parameters:\n    -----------\n    fasta_file : str\n        Path to the FASTA file\n        \n    Returns:\n    --------\n    Tuple[List[str], List[str]]\n        Tuple of (sequence_names, sequences)\n        \n    Raises:\n    -------\n    ValueError\n        If file doesn\'t contain exactly 2 sequences\n        If sequences are not of equal length\n    """\n    sequence_names = []\n    sequences = []\n    current_sequence = \'\'\n    current_name = \'\'\n    \n    try:\n        with open(fasta_file, \'r\') as file:\n            for line in file:\n                line = line.strip()\n                \n                if line.startswith(\'>\'):\n                    # Save previous sequence\n                    if current_sequence:\n                        sequences.append(current_sequence.upper())\n                        sequence_names.append(current_name)\n                    \n                    # Start new sequence\n                    current_name = line[1:].strip()\n                    current_sequence = \'\'\n                else:\n                    current_sequence += line\n            \n            # Add last sequence\n            if current_sequence:\n                sequences.append(current_sequence.upper())\n                sequence_names.append(current_name)\n    \n    except Exception as e:\n        raise ValueError(f"Error reading FASTA file: {e}")\n    \n    # Validate sequences\n    if len(sequences) != 2:\n        raise ValueError(f"Expected 2 sequences, found {len(sequences)}. "\n                        "This script requires pairwise alignments.")\n    \n    if len(sequences[0]) != len(sequences[1]):\n        raise ValueError(f"Sequences have different lengths: {len(sequences[0])} vs {len(sequences[1])}. "\n                        "Sequences must be pre-aligned.")\n    \n    return sequence_names, sequences\n\n\n# ============================================================================\n# SUBSTITUTION ANALYSIS\n# ============================================================================\n\ndef analyze_substitutions(sequences: List[str]) -> Dict:\n    """\n    Analyze nucleotide substitutions between two aligned sequences.\n    \n    Parameters:\n    -----------\n    sequences : List[str]\n        List containing exactly 2 aligned sequences\n        \n    Returns:\n    --------\n    Dict\n        Dictionary containing:\n        - substitutions: count of each substitution type\n        - positions: list of positions for each substitution type\n        - ts_count: total transition count\n        - tv_count: total transversion count\n        - ts_tv_ratio: transition/transversion ratio\n        - total_compared: number of positions compared\n        - identical: number of identical positions\n    """\n    # Initialize counters\n    substitutions = {sub_type: 0 for sub_type in SUBSTITUTION_TYPES}\n    positions = {sub_type: [] for sub_type in SUBSTITUTION_TYPES}\n    \n    ref_seq = sequences[0]\n    query_seq = sequences[1]\n    \n    total_compared = 0\n    identical = 0\n    \n    # Compare sequences position by position\n    for i in range(len(ref_seq)):\n        ref_base = ref_seq[i]\n        query_base = query_seq[i]\n        \n        # Skip gaps\n        if ref_base == \'-\' or query_base == \'-\':\n            continue\n        \n        # Skip non-standard bases\n        if ref_base not in \'ATGC\' or query_base not in \'ATGC\':\n            continue\n        \n        total_compared += 1\n        \n        if ref_base == query_base:\n            identical += 1\n            continue\n        \n        # Record substitution\n        substitution = f"{ref_base}_to_{query_base}"\n        if substitution in substitutions:\n            substitutions[substitution] += 1\n            positions[substitution].append(i + 1)  # 1-based position\n    \n    # Calculate transition and transversion counts\n    ts_count = sum(substitutions[sub] for sub in TRANSITIONS)\n    tv_count = sum(substitutions[sub] for sub in TRANSVERSIONS)\n    \n    # Calculate Ts/Tv ratio\n    ts_tv_ratio = ts_count / tv_count if tv_count > 0 else float(\'inf\')\n    \n    return {\n        \'substitutions\': substitutions,\n        \'positions\': positions,\n        \'ts_count\': ts_count,\n        \'tv_count\': tv_count,\n        \'ts_tv_ratio\': ts_tv_ratio,\n        \'total_compared\': total_compared,\n        \'identical\': identical\n    }\n\n\n# ============================================================================\n# EXCEL OUTPUT\n# ============================================================================\n\ndef create_substitution_excel(analysis_results: Dict, sequence_names: List[str], \n                             output_file: str, alignment_length: int):\n    """\n    Create an Excel file with substitution analysis results.\n    \n    Parameters:\n    -----------\n    analysis_results : Dict\n        Results from analyze_substitutions()\n    sequence_names : List[str]\n        Names of the two sequences analyzed\n    output_file : str\n        Path for the output Excel file\n    alignment_length : int\n        Total length of the alignment\n    """\n    workbook = openpyxl.Workbook()\n    \n    # Remove default sheet\n    if \'Sheet\' in workbook.sheetnames:\n        workbook.remove(workbook[\'Sheet\'])\n    \n    # ===== Sheet 1: Substitution Details =====\n    sheet_details = workbook.create_sheet(\'Substitution_Details\', 0)\n    \n    # Headers\n    headers = [\'Substitution\', \'Count\', \'Percentage\', \'Positions\']\n    sheet_details.append(headers)\n    \n    # Format headers\n    header_fill = PatternFill(start_color=\'366092\', end_color=\'366092\', fill_type=\'solid\')\n    for cell in sheet_details[1]:\n        cell.fill = header_fill\n        cell.font = Font(bold=True, color=\'FFFFFF\', size=11)\n        cell.alignment = Alignment(horizontal=\'center\', vertical=\'center\')\n    \n    # Add substitution data\n    total_substitutions = sum(analysis_results[\'substitutions\'].values())\n    \n    for sub_type in SUBSTITUTION_TYPES:\n        count = analysis_results[\'substitutions\'][sub_type]\n        percentage = (count / total_substitutions * 100) if total_substitutions > 0 else 0\n        positions = analysis_results[\'positions\'][sub_type]\n        positions_str = \', \'.join(map(str, positions)) if positions else \'None\'\n        \n        row = [sub_type, count, round(percentage, 4), positions_str]\n        sheet_details.append(row)\n    \n    # Add spacing\n    sheet_details.append([])\n    \n    # Add summary statistics\n    sheet_details.append([\'Category\', \'Value\', \'\', \'\'])\n    summary_row = sheet_details.max_row\n    sheet_details[summary_row][0].font = Font(bold=True)\n    sheet_details[summary_row][1].font = Font(bold=True)\n    \n    sheet_details.append([\'Transitions (Ts)\', analysis_results[\'ts_count\'], \'\', \'\'])\n    sheet_details.append([\'Transversions (Tv)\', analysis_results[\'tv_count\'], \'\', \'\'])\n    sheet_details.append([\'Ts/Tv Ratio\', round(analysis_results[\'ts_tv_ratio\'], 4), \'\', \'\'])\n    sheet_details.append([\'Total Substitutions\', total_substitutions, \'\', \'\'])\n    \n    # Format percentage column\n    for row in range(2, len(SUBSTITUTION_TYPES) + 2):\n        cell = sheet_details.cell(row=row, column=3)\n        cell.number_format = \'0.0000\'\n        cell.alignment = Alignment(horizontal=\'center\')\n    \n    # Adjust column widths\n    sheet_details.column_dimensions[\'A\'].width = 15\n    sheet_details.column_dimensions[\'B\'].width = 10\n    sheet_details.column_dimensions[\'C\'].width = 12\n    sheet_details.column_dimensions[\'D\'].width = 50\n    \n    # ===== Sheet 2: Summary =====\n    sheet_summary = workbook.create_sheet(\'Summary\', 1)\n    \n    summary_data = [\n        [\'Metric\', \'Value\'],\n        [\'Reference Sequence\', sequence_names[0]],\n        [\'Query Sequence\', sequence_names[1]],\n        [\'Alignment Length\', alignment_length],\n        [\'Positions Compared\', analysis_results[\'total_compared\']],\n        [\'Identical Positions\', analysis_results[\'identical\']],\n        [\'Total Substitutions\', total_substitutions],\n        [\'Identity (%)\', round(analysis_results[\'identical\'] / analysis_results[\'total_compared\'] * 100, 2) \n         if analysis_results[\'total_compared\'] > 0 else 0],\n        [\'Substitution Rate (%)\', round(total_substitutions / analysis_results[\'total_compared\'] * 100, 2)\n         if analysis_results[\'total_compared\'] > 0 else 0],\n        [\'Transitions (Ts)\', analysis_results[\'ts_count\']],\n        [\'Transversions (Tv)\', analysis_results[\'tv_count\']],\n        [\'Ts/Tv Ratio\', round(analysis_results[\'ts_tv_ratio\'], 4)]\n    ]\n    \n    for row_data in summary_data:\n        sheet_summary.append(row_data)\n    \n    # Format summary sheet\n    for cell in sheet_summary[1]:\n        cell.fill = header_fill\n        cell.font = Font(bold=True, color=\'FFFFFF\', size=11)\n        cell.alignment = Alignment(horizontal=\'center\')\n    \n    for row in range(2, sheet_summary.max_row + 1):\n        sheet_summary.cell(row=row, column=1).font = Font(bold=True)\n    \n    sheet_summary.column_dimensions[\'A\'].width = 25\n    sheet_summary.column_dimensions[\'B\'].width = 40\n    \n    # Save workbook\n    workbook.save(output_file)\n\n\n# ============================================================================\n# FILE PROCESSING\n# ============================================================================\n\ndef process_single_fasta_file(fasta_file: str) -> Tuple[str, Dict]:\n    """\n    Process a single FASTA file and analyze substitutions.\n    \n    Parameters:\n    -----------\n    fasta_file : str\n        Path to the FASTA file\n        \n    Returns:\n    --------\n    Tuple[str, Dict]\n        Tuple of (output filename, analysis results)\n    """\n    print(f"\\nProcessing: {fasta_file}")\n    \n    try:\n        # Load sequences\n        sequence_names, sequences = load_fasta_sequences(fasta_file)\n        print(f"  - Reference: {sequence_names[0]}")\n        print(f"  - Query: {sequence_names[1]}")\n        print(f"  - Alignment length: {len(sequences[0]):,} bp")\n        \n        # Analyze substitutions\n        results = analyze_substitutions(sequences)\n        \n        total_subs = sum(results[\'substitutions\'].values())\n        print(f"  - Total substitutions: {total_subs:,}")\n        print(f"  - Transitions: {results[\'ts_count\']:,}")\n        print(f"  - Transversions: {results[\'tv_count\']:,}")\n        print(f"  - Ts/Tv ratio: {results[\'ts_tv_ratio\']:.4f}")\n        \n        # Generate output filename\n        base_name = Path(fasta_file).stem\n        output_file = f"{base_name}_Substitutions.xlsx"\n        \n        # Create Excel file\n        create_substitution_excel(results, sequence_names, output_file, len(sequences[0]))\n        \n        print(f"  ✓ Saved: {output_file}")\n        \n        return output_file, results\n        \n    except Exception as e:\n        print(f"  ❌ ERROR: {e}")\n        return None, None\n\n\ndef find_fasta_files(directory: str = None) -> List[str]:\n    """\n    Find all FASTA files in the specified directory.\n    \n    Parameters:\n    -----------\n    directory : str, optional\n        Directory to search (default: current working directory)\n        \n    Returns:\n    --------\n    List[str]\n        List of FASTA file paths\n    """\n    if directory is None:\n        directory = os.getcwd()\n    \n    # Supported FASTA file extensions\n    fasta_extensions = (\'.fasta\', \'.fa\', \'.fna\', \'.faa\')\n    \n    fasta_files = [\n        os.path.join(directory, f) \n        for f in os.listdir(directory) \n        if f.lower().endswith(fasta_extensions)\n    ]\n    \n    return sorted(fasta_files)\n\n\n# ============================================================================\n# MERGE RESULTS\n# ============================================================================\n\ndef merge_substitution_files(sub_files: List[str], output_file: str = \'Merged_Substitution_Analysis.xlsx\'):\n    """\n    Merge individual substitution analysis files into a single comparative analysis file.\n    \n    Parameters:\n    -----------\n    sub_files : List[str]\n        List of substitution Excel file paths to merge\n    output_file : str\n        Name of the output merged file\n    """\n    print(f"\\n{\'=\'*70}")\n    print("MERGING SUBSTITUTION ANALYSIS FILES")\n    print(f"{\'=\'*70}")\n    \n    if not sub_files:\n        print("No substitution files to merge.")\n        return\n    \n    # Collect data from all files\n    all_data = {}\n    file_names = []\n    \n    for filename in sub_files:\n        print(f"  - Adding: {filename}")\n        \n        try:\n            workbook = openpyxl.load_workbook(filename)\n            sheet = workbook[\'Substitution_Details\']\n            \n            # Get file identifier\n            file_id = Path(filename).stem.replace(\'_Substitutions\', \'\')\n            file_names.append(file_id)\n            \n            # Extract substitution counts\n            data = {}\n            for row in range(2, 14):  # Rows 2-13 contain substitution data\n                sub_type = sheet.cell(row=row, column=1).value\n                count = sheet.cell(row=row, column=2).value\n                data[sub_type] = count\n            \n            # Extract Ts, Tv, and ratio\n            for row in range(15, sheet.max_row + 1):\n                category = sheet.cell(row=row, column=1).value\n                value = sheet.cell(row=row, column=2).value\n                if category in [\'Transitions (Ts)\', \'Transversions (Tv)\', \'Ts/Tv Ratio\']:\n                    data[category] = value\n            \n            all_data[file_id] = data\n            workbook.close()\n            \n        except Exception as e:\n            print(f"  WARNING: Error reading {filename}: {e}")\n            continue\n    \n    if not all_data:\n        print("  ERROR: No data to merge.")\n        return\n    \n    # Create merged workbook\n    merged_wb = openpyxl.Workbook()\n    merged_sheet = merged_wb.active\n    merged_sheet.title = \'Merged_Substitutions\'\n    \n    # Build header row\n    header = [\'Substitution_Type\'] + file_names\n    merged_sheet.append(header)\n    \n    # Add substitution data\n    for sub_type in SUBSTITUTION_TYPES:\n        row_data = [sub_type]\n        for file_id in file_names:\n            row_data.append(all_data[file_id].get(sub_type, 0))\n        merged_sheet.append(row_data)\n    \n    # Add spacing\n    merged_sheet.append([])\n    \n    # Add summary statistics\n    for category in [\'Transitions (Ts)\', \'Transversions (Tv)\', \'Ts/Tv Ratio\']:\n        row_data = [category]\n        for file_id in file_names:\n            row_data.append(all_data[file_id].get(category, 0))\n        merged_sheet.append(row_data)\n    \n    # Format the merged sheet\n    header_fill = PatternFill(start_color=\'366092\', end_color=\'366092\', fill_type=\'solid\')\n    \n    for cell in merged_sheet[1]:\n        cell.fill = header_fill\n        cell.font = Font(bold=True, color=\'FFFFFF\', size=11)\n        cell.alignment = Alignment(horizontal=\'center\', vertical=\'center\')\n    \n    # Format data cells\n    for row in merged_sheet.iter_rows(min_row=2, max_row=merged_sheet.max_row):\n        row[0].font = Font(bold=True)\n        row[0].alignment = Alignment(horizontal=\'left\')\n        \n        for cell in row[1:]:\n            cell.alignment = Alignment(horizontal=\'center\')\n    \n    # Adjust column widths\n    merged_sheet.column_dimensions[\'A\'].width = 20\n    for col_idx in range(2, len(file_names) + 2):\n        col_letter = merged_sheet.cell(row=1, column=col_idx).column_letter\n        merged_sheet.column_dimensions[col_letter].width = 15\n    \n    # Freeze panes\n    merged_sheet.freeze_panes = \'B2\'\n    \n    # Save merged file\n    merged_wb.save(output_file)\n    \n    print(f"\\n  ✓ Merged analysis saved: {output_file}")\n    print(f"  - Total alignments compared: {len(file_names)}")\n\n\n# ============================================================================\n# MAIN PIPELINE\n# ============================================================================\n\ndef main():\n    """\n    Main pipeline execution function.\n    \n    Workflow:\n    1. Find all FASTA files in working directory\n    2. Process each file to analyze substitutions\n    3. Merge all results into comparative analysis\n    """\n    print(f"\\n{\'=\'*70}")\n    print("NUCLEOTIDE SUBSTITUTION ANALYSIS PIPELINE")\n    print(f"{\'=\'*70}")\n    \n    # Get working directory\n    working_dir = os.getcwd()\n    print(f"\\nWorking directory: {working_dir}")\n    \n    # Find FASTA files\n    fasta_files = find_fasta_files(working_dir)\n    \n    if not fasta_files:\n        print("\\n❌ ERROR: No FASTA files found!")\n        print("Please place FASTA alignment files (.fasta, .fa, .fna) in the working directory.")\n        return\n    \n    print(f"\\nFound {len(fasta_files)} FASTA file(s):")\n    for ff in fasta_files:\n        print(f"  - {os.path.basename(ff)}")\n    \n    # Process each FASTA file\n    print(f"\\n{\'=\'*70}")\n    print("ANALYZING NUCLEOTIDE SUBSTITUTIONS")\n    print(f"{\'=\'*70}")\n    \n    sub_files = []\n    for fasta_file in fasta_files:\n        try:\n            output_file, _ = process_single_fasta_file(fasta_file)\n            if output_file:\n                sub_files.append(output_file)\n        except Exception as e:\n            print(f"  ❌ ERROR processing {fasta_file}: {e}")\n            continue\n    \n    # Merge results\n    if sub_files:\n        merge_substitution_files(sub_files)\n    \n    # Summary\n    print(f"\\n{\'=\'*70}")\n    print("ANALYSIS COMPLETE")\n    print(f"{\'=\'*70}")\n    print(f"✓ Successfully processed: {len(sub_files)} alignment(s)")\n    print(f"✓ Individual substitution files: {len(sub_files)}")\n    if sub_files:\n        print(f"✓ Merged analysis file: Merged_Substitution_Analysis.xlsx")\n    print(f"\\nAll output files saved in: {working_dir}")\n    print(f"{\'=\'*70}\\n")\n\n\n# ============================================================================\n# SCRIPT ENTRY POINT\n# ============================================================================\n\nif True:\n    try:\n        main()\n    except KeyboardInterrupt:\n        print("\\n\\n⚠ Analysis interrupted by user.")\n        sys.exit(0)\n    except Exception as e:\n        print(f"\\n\\n❌ FATAL ERROR: {e}")\n        import traceback\n        traceback.print_exc()\n        sys.exit(1)'

def run_mode_6():
    """
    Mode 6: SNP Analysis
    
    This function executes the original script code for Mode 6.
    All logic and output formatting is preserved from the original script.
    
    Returns:
        None - Outputs are saved as Excel/Word files
        
    Raises:
        FileNotFoundError: If required input files are not found
        Exception: For other errors during execution
    """
    print("\n" + "="*80)
    print(f"MODE 6: SNP Analysis")
    print("="*80 + "\n")
    
    exec(_MODE_6_CODE, globals())


# ============================================================================
# MODE 7: Intron Analysis
# ============================================================================

_MODE_7_CODE = '#!/usr/bin/env python3\n"""\nGene and tRNA Intron Extraction from GenBank Files\n\nThis script extracts intron positions and lengths from both gene (CDS/gene features)\nand tRNA features in GenBank format files. Results are saved in a single Excel file\nwith separate sheets for gene introns and tRNA introns.\n\nAuthor: [Your Name]\nDate: December 2025\nVersion: 2.0\n\nRequirements:\n    - Python 3.7+\n    - biopython\n    - pandas\n    - openpyxl\n\nInstallation:\n    pip install biopython pandas openpyxl\n\nUsage:\n    python extract_introns.py\n\nOutput:\n    intron_data.xlsx - Excel file with two sheets:\n        - Sheet 1: Gene Introns (CDS/gene features)\n        - Sheet 2: tRNA Introns (tRNA features)\n"""\n\nimport os\nimport sys\nimport logging\nfrom datetime import datetime\nfrom typing import List, Tuple\nimport pandas as pd\nfrom Bio import SeqIO\nfrom Bio.SeqFeature import CompoundLocation\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format=\'%(asctime)s - %(levelname)s - %(message)s\',\n    handlers=[\n        logging.FileHandler(\'intron_extraction.log\', encoding=\'utf-8\'),\n        logging.StreamHandler(sys.stdout)\n    ]\n)\nlogger = logging.getLogger(__name__)\n\n# Handle Windows console encoding\nif sys.platform == \'win32\':\n    try:\n        if hasattr(sys.stdout, \'reconfigure\'):\n            sys.stdout.reconfigure(encoding=\'utf-8\')\n    except (AttributeError, OSError):\n        pass\n\n# Global constants\nMAX_INTRON_LENGTH = 15000\nOUTPUT_FILENAME = "intron_data.xlsx"\nVALID_EXTENSIONS = (\'.gb\', \'.gbff\', \'.genbank\')\n\n\ndef extract_gene_introns_from_genbank(gb_file: str) -> List[List]:\n    """\n    Extract gene/CDS intron information from a GenBank file.\n    \n    Args:\n        gb_file (str): Path to GenBank format file\n        \n    Returns:\n        List[List]: List of gene records with intron data\n    """\n    gene_introns = []\n    \n    for record in SeqIO.parse(gb_file, "genbank"):\n        accession = record.id\n        species = record.annotations.get(\'organism\', \'Unknown species\')\n        \n        for feature in record.features:\n            if feature.type in [\'CDS\', \'gene\']:\n                gene = feature.qualifiers.get(\'gene\', [\'Unknown\'])[0]\n                \n                if isinstance(feature.location, CompoundLocation):\n                    exons = sorted(feature.location.parts, key=lambda x: x.start)\n                    intron_info = []\n                    \n                    for i in range(len(exons) - 1):\n                        intron_start = int(exons[i].end) + 1\n                        intron_end = int(exons[i + 1].start)\n                        intron_length = intron_end - intron_start + 1\n                        \n                        if 0 < intron_length <= MAX_INTRON_LENGTH:\n                            intron_info.extend([\n                                f"Intron {i + 1}",\n                                intron_start,\n                                intron_end,\n                                intron_length\n                            ])\n                    \n                    if intron_info:\n                        gene_data = [accession, species, gene] + intron_info\n                        gene_introns.append(gene_data)\n    \n    return gene_introns\n\n\ndef extract_tRNA_introns_from_genbank(gb_file: str) -> List[List]:\n    """\n    Extract tRNA intron information from a GenBank file.\n    \n    Args:\n        gb_file (str): Path to GenBank format file\n        \n    Returns:\n        List[List]: List of tRNA records with intron data\n    """\n    trna_introns = []\n    \n    for record in SeqIO.parse(gb_file, "genbank"):\n        accession = record.id\n        species = record.annotations.get(\'organism\', \'Unknown species\')\n        \n        for feature in record.features:\n            if feature.type == \'tRNA\':\n                gene = feature.qualifiers.get(\'gene\', feature.qualifiers.get(\'product\', [\'Unknown\']))[0]\n                \n                if isinstance(feature.location, CompoundLocation):\n                    exons = sorted(feature.location.parts, key=lambda x: x.start)\n                    intron_info = []\n                    \n                    for i in range(len(exons) - 1):\n                        intron_start = exons[i].end + 1\n                        intron_end = exons[i + 1].start - 1\n                        intron_length = int(intron_end - intron_start + 1)\n                        \n                        if intron_length > 0 and intron_length <= MAX_INTRON_LENGTH:\n                            intron_info.extend([\n                                f"Intron {i + 1}",\n                                int(intron_start),\n                                int(intron_end),\n                                intron_length\n                            ])\n                    \n                    if intron_info:\n                        gene_data = [accession, species, gene] + intron_info\n                        trna_introns.append(gene_data)\n    \n    return trna_introns\n\n\ndef create_combined_excel_output(gene_data: List[List], trna_data: List[List], \n                                 output_excel: str) -> None:\n    """\n    Create Excel output with separate sheets for gene and tRNA introns.\n    \n    Args:\n        gene_data (List[List]): Gene intron data rows\n        trna_data (List[List]): tRNA intron data rows\n        output_excel (str): Output Excel filename\n    """\n    with pd.ExcelWriter(output_excel, engine=\'openpyxl\') as writer:\n        from openpyxl.styles import Font, Alignment\n        \n        # Define fonts\n        header_font = Font(bold=True)\n        header_alignment = Alignment(horizontal=\'center\')\n        italic_font = Font(italic=True)\n        regular_font = Font(italic=False)\n        center_alignment = Alignment(horizontal=\'center\')\n        left_alignment = Alignment(horizontal=\'left\')\n        \n        # Create Gene Introns sheet\n        if gene_data:\n            max_introns = max((len(row) - 3) // 4 for row in gene_data)\n            columns = ["Accession", "Species", "Gene"]\n            for i in range(1, max_introns + 1):\n                columns += [f"Intron {i} #", f"Intron {i} Start", f"Intron {i} End", f"Intron {i} Length"]\n            \n            for row in gene_data:\n                while len(row) < len(columns):\n                    row.extend(["", "", "", ""])\n            \n            df_gene = pd.DataFrame(gene_data, columns=columns)\n            df_gene.to_excel(writer, index=False, sheet_name=\'Gene Introns\')\n            \n            worksheet = writer.sheets[\'Gene Introns\']\n            \n            # Format header row\n            for cell in worksheet[1]:\n                cell.font = header_font\n                cell.alignment = header_alignment\n            \n            # Format data rows\n            for row in worksheet.iter_rows(min_row=2, max_row=worksheet.max_row):\n                # Column A: Accession (regular, left-aligned)\n                row[0].font = regular_font\n                row[0].alignment = left_alignment\n                \n                # Column B: Species (italic, left-aligned)\n                row[1].font = italic_font\n                row[1].alignment = left_alignment\n                \n                # Column C: Gene (italic, left-aligned)\n                row[2].font = italic_font\n                row[2].alignment = left_alignment\n                \n                # Remaining columns: numbers (regular, centered)\n                for cell in row[3:]:\n                    cell.font = regular_font\n                    cell.alignment = center_alignment\n            \n            # Auto-adjust column widths\n            for column in worksheet.columns:\n                max_length = 0\n                column_letter = column[0].column_letter\n                for cell in column:\n                    if cell.value:\n                        max_length = max(max_length, len(str(cell.value)))\n                worksheet.column_dimensions[column_letter].width = min(max_length + 3, 50)\n        \n        # Create tRNA Introns sheet\n        if trna_data:\n            max_introns = max((len(row) - 3) // 4 for row in trna_data)\n            columns = ["Accession", "Species", "tRNA Gene"]\n            for i in range(1, max_introns + 1):\n                columns += [f"Intron {i} #", f"Intron {i} Start", f"Intron {i} End", f"Intron {i} Length"]\n            \n            for row in trna_data:\n                while len(row) < len(columns):\n                    row.extend(["", "", "", ""])\n            \n            df_trna = pd.DataFrame(trna_data, columns=columns)\n            df_trna.to_excel(writer, index=False, sheet_name=\'tRNA Introns\')\n            \n            worksheet = writer.sheets[\'tRNA Introns\']\n            \n            # Format header row\n            for cell in worksheet[1]:\n                cell.font = header_font\n                cell.alignment = header_alignment\n            \n            # Format data rows\n            for row in worksheet.iter_rows(min_row=2, max_row=worksheet.max_row):\n                # Column A: Accession (regular, left-aligned)\n                row[0].font = regular_font\n                row[0].alignment = left_alignment\n                \n                # Column B: Species (italic, left-aligned)\n                row[1].font = italic_font\n                row[1].alignment = left_alignment\n                \n                # Column C: tRNA Gene (italic, left-aligned)\n                row[2].font = italic_font\n                row[2].alignment = left_alignment\n                \n                # Remaining columns: numbers (regular, centered)\n                for cell in row[3:]:\n                    cell.font = regular_font\n                    cell.alignment = center_alignment\n            \n            # Auto-adjust column widths\n            for column in worksheet.columns:\n                max_length = 0\n                column_letter = column[0].column_letter\n                for cell in column:\n                    if cell.value:\n                        max_length = max(max_length, len(str(cell.value)))\n                worksheet.column_dimensions[column_letter].width = min(max_length + 3, 50)\n\n\ndef process_all_genbank_files(output: str = OUTPUT_FILENAME) -> None:\n    """\n    Process all GenBank files in the current working directory.\n    \n    Args:\n        output (str): Output Excel filename\n    """\n    logger.info("="*70)\n    logger.info("INTRON EXTRACTION ANALYSIS")\n    logger.info("="*70)\n    \n    all_gene_introns = []\n    all_trna_introns = []\n    current_dir = os.getcwd()\n    \n    gb_files = [f for f in os.listdir(current_dir) if f.endswith(VALID_EXTENSIONS)]\n    \n    if not gb_files:\n        logger.error(f"No GenBank files found in {current_dir}")\n        raise FileNotFoundError("No GenBank files (.gb, .gbff, .genbank) found")\n    \n    logger.info(f"Found {len(gb_files)} GenBank file(s)")\n    logger.info("-"*70)\n    \n    # Process each file\n    for idx, gb_file in enumerate(gb_files, 1):\n        logger.info(f"[{idx}/{len(gb_files)}] Processing: {gb_file}")\n        try:\n            gene_rows = extract_gene_introns_from_genbank(gb_file)\n            trna_rows = extract_tRNA_introns_from_genbank(gb_file)\n            all_gene_introns.extend(gene_rows)\n            all_trna_introns.extend(trna_rows)\n            logger.info(f"  Genes: {len(gene_rows)}, tRNAs: {len(trna_rows)}")\n        except Exception as e:\n            logger.warning(f"  Skipping {gb_file}: {str(e)}")\n            continue\n    \n    logger.info("-"*70)\n    \n    if not all_gene_introns and not all_trna_introns:\n        raise ValueError("No introns found in any file")\n    \n    # Create Excel file\n    logger.info(f"Creating: {output}")\n    create_combined_excel_output(all_gene_introns, all_trna_introns, output)\n    \n    logger.info("="*70)\n    logger.info(f"SUCCESS: {output} created")\n    logger.info(f"  Gene introns: {len(all_gene_introns)}")\n    logger.info(f"  tRNA introns: {len(all_trna_introns)}")\n    logger.info("="*70)\n\n\ndef main():\n    """Main execution function."""\n    try:\n        process_all_genbank_files()\n    except Exception as e:\n        logger.error(f"Error: {str(e)}")\n        sys.exit(1)\n\n\nif True:\n    main()'

def run_mode_7():
    """
    Mode 7: Intron Analysis
    
    This function executes the original script code for Mode 7.
    All logic and output formatting is preserved from the original script.
    
    Returns:
        None - Outputs are saved as Excel/Word files
        
    Raises:
        FileNotFoundError: If required input files are not found
        Exception: For other errors during execution
    """
    print("\n" + "="*80)
    print(f"MODE 7: Intron Analysis")
    print("="*80 + "\n")
    
    exec(_MODE_7_CODE, globals())



# ============================================================================
# CONVENIENCE FUNCTIONS
# ============================================================================

def run_all_modes(skip_missing=True):
    """
    Run all 7 analysis modes in sequence.
    
    This function executes all modes and provides a summary of results.
    It automatically detects available input files and skips modes where
    required files are missing (if skip_missing=True).
    
    Args:
        skip_missing (bool): If True, skip modes with missing input files.
                            If False, raise errors for missing files.
    
    Returns:
        dict: Summary with keys 'completed', 'skipped', 'failed'
    """
    print("="*80)
    print("RUNNING ALL CHLOROPLAST ANALYSIS MODES")
    print("="*80)
    print()
    
    # Check available files
    gb_files = [f for f in os.listdir('.') if f.endswith(('.gb', '.gbk', '.genbank', '.gbff'))]
    fasta_files = [f for f in os.listdir('.') if f.endswith(('.fasta', '.fa', '.fna', '.fas'))]
    
    print("Files detected:")
    print(f"  GenBank files: {len(gb_files)}")
    print(f"  FASTA files: {len(fasta_files)}")
    print()
    
    summary = {
        'completed': [],
        'skipped': [],
        'failed': []
    }
    
    # Modes 1-5, 7: GenBank analyses
    if gb_files:
        for mode_num in [1, 2, 3, 4, 5, 7]:
            try:
                globals()[f'run_mode_{mode_num}']()
                summary['completed'].append(mode_num)
                print(f"✓ Mode {mode_num} completed\n")
            except Exception as e:
                summary['failed'].append(mode_num)
                print(f"⚠️  Mode {mode_num} failed: {e}\n")
                if not skip_missing:
                    raise
    else:
        for mode_num in [1, 2, 3, 4, 5, 7]:
            summary['skipped'].append(mode_num)
        print("⚠️  Modes 1-5, 7 skipped: No GenBank files found\n")
    
    # Mode 6: SNP analysis
    if fasta_files:
        try:
            run_mode_6()
            summary['completed'].append(6)
            print("✓ Mode 6 completed\n")
        except Exception as e:
            summary['failed'].append(6)
            print(f"⚠️  Mode 6 failed: {e}\n")
            if not skip_missing:
                raise
    else:
        summary['skipped'].append(6)
        print("⚠️  Mode 6 skipped: No FASTA files found\n")
    
    # Print summary
    print("="*80)
    print("ANALYSIS SUMMARY")
    print("="*80)
    print(f"Completed modes: {len(summary['completed'])} - {summary['completed']}")
    print(f"Skipped modes: {len(summary['skipped'])} - {summary['skipped']}")
    print(f"Failed modes: {len(summary['failed'])} - {summary['failed']}")
    print("="*80)
    
    return summary


def get_mode_info(mode_num=None):
    """Get information about available modes."""
    mode_info = {
        1: {'name': 'Gene Content Analysis', 'input': '*.gb files', 'output': 'Chloroplast_Gene_Analysis_[timestamp].xlsx'},
        2: {'name': 'Gene Length Analysis', 'input': '*.gb files', 'output': 'Gene_Length_Analysis_[timestamp].xlsx'},
        3: {'name': 'IR Boundary Analysis', 'input': '*.gb files', 'output': 'Comparative_Analysis_[timestamp].xlsx'},
        4: {'name': 'Codon Usage Analysis', 'input': '*.gb files', 'output': 'Codon_Usage_[timestamp].xlsx'},
        5: {'name': 'Amino Acid Analysis', 'input': '*.gb files', 'output': 'Amino_Acid_[timestamp].xlsx'},
        6: {'name': 'SNP Analysis', 'input': '*.fasta files', 'output': 'SNP_Analysis_[timestamp].xlsx'},
        7: {'name': 'Intron Analysis', 'input': '*.gb files', 'output': 'Intron_Analysis_[timestamp].xlsx'}
    }
    
    if mode_num is not None:
        if mode_num in mode_info:
            info = mode_info[mode_num]
            return f"Mode {mode_num}: {info['name']}\nInput: {info['input']}\nOutput: {info['output']}"
        else:
            return f"Error: Mode {mode_num} does not exist."
    else:
        return "\n".join([f"Mode {n}: {i['name']}" for n, i in mode_info.items()])


def list_modes():
    """Print a list of all available modes."""
    print(get_mode_info())


__version__ = '2.0.2'
__author__ = 'Abdullah'
__date__ = 'December 2025'

__all__ = [
    'run_mode_1', 'run_mode_2', 'run_mode_3',
    'run_mode_4', 'run_mode_5', 'run_mode_6', 'run_mode_7',
    'run_all_modes', 'get_mode_info', 'list_modes'
]


if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser(description='Chloroplast Genome Analysis Module (7 modes)')
    parser.add_argument('--mode', '-m', type=int, nargs='+', choices=range(1, 8))
    parser.add_argument('--all', '-a', action='store_true')
    parser.add_argument('--list', '-l', action='store_true')
    parser.add_argument('--info', '-i', type=int, choices=range(1, 8))
    args = parser.parse_args()
    
    if args.list:
        list_modes()
    elif args.info is not None:
        print(get_mode_info(args.info))
    elif args.all:
        run_all_modes()
    elif args.mode:
        for mode_num in args.mode:
            try:
                globals()[f'run_mode_{mode_num}']()
                print(f"✓ Mode {mode_num} completed\n")
            except Exception as e:
                print(f"⚠️  Mode {mode_num} failed: {e}\n")
    else:
        parser.print_help()
